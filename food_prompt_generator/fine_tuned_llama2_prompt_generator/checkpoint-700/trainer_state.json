{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.5,
  "eval_steps": 50,
  "global_step": 700,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0035714285714285713,
      "grad_norm": 1.2351223230361938,
      "learning_rate": 0.0,
      "loss": 4.4977,
      "step": 1
    },
    {
      "epoch": 0.007142857142857143,
      "grad_norm": 1.142757773399353,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 4.2449,
      "step": 2
    },
    {
      "epoch": 0.010714285714285714,
      "grad_norm": 1.1618402004241943,
      "learning_rate": 4.000000000000001e-06,
      "loss": 4.1516,
      "step": 3
    },
    {
      "epoch": 0.014285714285714285,
      "grad_norm": 1.2743682861328125,
      "learning_rate": 6e-06,
      "loss": 4.3749,
      "step": 4
    },
    {
      "epoch": 0.017857142857142856,
      "grad_norm": 1.1161952018737793,
      "learning_rate": 8.000000000000001e-06,
      "loss": 4.0766,
      "step": 5
    },
    {
      "epoch": 0.02142857142857143,
      "grad_norm": 1.237971305847168,
      "learning_rate": 1e-05,
      "loss": 4.2567,
      "step": 6
    },
    {
      "epoch": 0.025,
      "grad_norm": 1.1448726654052734,
      "learning_rate": 1.2e-05,
      "loss": 4.2172,
      "step": 7
    },
    {
      "epoch": 0.02857142857142857,
      "grad_norm": 1.223588466644287,
      "learning_rate": 1.4e-05,
      "loss": 4.3423,
      "step": 8
    },
    {
      "epoch": 0.03214285714285714,
      "grad_norm": 1.1014832258224487,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 3.8955,
      "step": 9
    },
    {
      "epoch": 0.03571428571428571,
      "grad_norm": 1.2143946886062622,
      "learning_rate": 1.8e-05,
      "loss": 4.0908,
      "step": 10
    },
    {
      "epoch": 0.039285714285714285,
      "grad_norm": 1.319791555404663,
      "learning_rate": 2e-05,
      "loss": 4.2406,
      "step": 11
    },
    {
      "epoch": 0.04285714285714286,
      "grad_norm": 1.2103867530822754,
      "learning_rate": 1.9975903614457833e-05,
      "loss": 3.9583,
      "step": 12
    },
    {
      "epoch": 0.04642857142857143,
      "grad_norm": 1.2164217233657837,
      "learning_rate": 1.9951807228915665e-05,
      "loss": 4.0441,
      "step": 13
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.3159626722335815,
      "learning_rate": 1.9927710843373497e-05,
      "loss": 3.9948,
      "step": 14
    },
    {
      "epoch": 0.05357142857142857,
      "grad_norm": 1.5581860542297363,
      "learning_rate": 1.9903614457831325e-05,
      "loss": 4.2483,
      "step": 15
    },
    {
      "epoch": 0.05714285714285714,
      "grad_norm": 1.3834818601608276,
      "learning_rate": 1.987951807228916e-05,
      "loss": 3.9568,
      "step": 16
    },
    {
      "epoch": 0.060714285714285714,
      "grad_norm": 1.4401079416275024,
      "learning_rate": 1.985542168674699e-05,
      "loss": 4.0513,
      "step": 17
    },
    {
      "epoch": 0.06428571428571428,
      "grad_norm": 1.5064538717269897,
      "learning_rate": 1.983132530120482e-05,
      "loss": 3.9104,
      "step": 18
    },
    {
      "epoch": 0.06785714285714285,
      "grad_norm": 1.5647220611572266,
      "learning_rate": 1.9807228915662652e-05,
      "loss": 3.9984,
      "step": 19
    },
    {
      "epoch": 0.07142857142857142,
      "grad_norm": 1.5998917818069458,
      "learning_rate": 1.9783132530120484e-05,
      "loss": 4.0516,
      "step": 20
    },
    {
      "epoch": 0.075,
      "grad_norm": 1.5841845273971558,
      "learning_rate": 1.9759036144578312e-05,
      "loss": 3.8885,
      "step": 21
    },
    {
      "epoch": 0.07857142857142857,
      "grad_norm": 1.5619786977767944,
      "learning_rate": 1.9734939759036148e-05,
      "loss": 3.7881,
      "step": 22
    },
    {
      "epoch": 0.08214285714285714,
      "grad_norm": 1.6028382778167725,
      "learning_rate": 1.9710843373493976e-05,
      "loss": 3.7501,
      "step": 23
    },
    {
      "epoch": 0.08571428571428572,
      "grad_norm": 1.7312976121902466,
      "learning_rate": 1.9686746987951808e-05,
      "loss": 3.9056,
      "step": 24
    },
    {
      "epoch": 0.08928571428571429,
      "grad_norm": 1.6884418725967407,
      "learning_rate": 1.966265060240964e-05,
      "loss": 3.8343,
      "step": 25
    },
    {
      "epoch": 0.09285714285714286,
      "grad_norm": 1.657343864440918,
      "learning_rate": 1.963855421686747e-05,
      "loss": 3.7759,
      "step": 26
    },
    {
      "epoch": 0.09642857142857143,
      "grad_norm": 1.7672631740570068,
      "learning_rate": 1.9614457831325303e-05,
      "loss": 3.6951,
      "step": 27
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.8270766735076904,
      "learning_rate": 1.9590361445783135e-05,
      "loss": 3.8563,
      "step": 28
    },
    {
      "epoch": 0.10357142857142858,
      "grad_norm": 1.6442331075668335,
      "learning_rate": 1.9566265060240967e-05,
      "loss": 3.5617,
      "step": 29
    },
    {
      "epoch": 0.10714285714285714,
      "grad_norm": 1.861194133758545,
      "learning_rate": 1.9542168674698795e-05,
      "loss": 3.7459,
      "step": 30
    },
    {
      "epoch": 0.11071428571428571,
      "grad_norm": 1.996978759765625,
      "learning_rate": 1.951807228915663e-05,
      "loss": 3.7912,
      "step": 31
    },
    {
      "epoch": 0.11428571428571428,
      "grad_norm": 1.8723829984664917,
      "learning_rate": 1.949397590361446e-05,
      "loss": 3.6466,
      "step": 32
    },
    {
      "epoch": 0.11785714285714285,
      "grad_norm": 1.6257067918777466,
      "learning_rate": 1.946987951807229e-05,
      "loss": 3.4698,
      "step": 33
    },
    {
      "epoch": 0.12142857142857143,
      "grad_norm": 2.0420496463775635,
      "learning_rate": 1.9445783132530122e-05,
      "loss": 3.8206,
      "step": 34
    },
    {
      "epoch": 0.125,
      "grad_norm": 1.7446900606155396,
      "learning_rate": 1.9421686746987954e-05,
      "loss": 3.5167,
      "step": 35
    },
    {
      "epoch": 0.12857142857142856,
      "grad_norm": 1.8713101148605347,
      "learning_rate": 1.9397590361445785e-05,
      "loss": 3.6069,
      "step": 36
    },
    {
      "epoch": 0.13214285714285715,
      "grad_norm": 2.0387582778930664,
      "learning_rate": 1.9373493975903617e-05,
      "loss": 3.5755,
      "step": 37
    },
    {
      "epoch": 0.1357142857142857,
      "grad_norm": 1.8597904443740845,
      "learning_rate": 1.9349397590361446e-05,
      "loss": 3.3767,
      "step": 38
    },
    {
      "epoch": 0.1392857142857143,
      "grad_norm": 1.8979336023330688,
      "learning_rate": 1.9325301204819277e-05,
      "loss": 3.5736,
      "step": 39
    },
    {
      "epoch": 0.14285714285714285,
      "grad_norm": 1.84732186794281,
      "learning_rate": 1.930120481927711e-05,
      "loss": 3.3367,
      "step": 40
    },
    {
      "epoch": 0.14642857142857144,
      "grad_norm": 2.1052732467651367,
      "learning_rate": 1.927710843373494e-05,
      "loss": 3.5508,
      "step": 41
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.1071627140045166,
      "learning_rate": 1.9253012048192773e-05,
      "loss": 3.5187,
      "step": 42
    },
    {
      "epoch": 0.15357142857142858,
      "grad_norm": 2.019829273223877,
      "learning_rate": 1.9228915662650604e-05,
      "loss": 3.4967,
      "step": 43
    },
    {
      "epoch": 0.15714285714285714,
      "grad_norm": 1.8837368488311768,
      "learning_rate": 1.9204819277108436e-05,
      "loss": 3.3049,
      "step": 44
    },
    {
      "epoch": 0.16071428571428573,
      "grad_norm": 1.8147345781326294,
      "learning_rate": 1.9180722891566265e-05,
      "loss": 3.2879,
      "step": 45
    },
    {
      "epoch": 0.16428571428571428,
      "grad_norm": 2.0287275314331055,
      "learning_rate": 1.91566265060241e-05,
      "loss": 3.3731,
      "step": 46
    },
    {
      "epoch": 0.16785714285714284,
      "grad_norm": 1.9595811367034912,
      "learning_rate": 1.9132530120481928e-05,
      "loss": 3.226,
      "step": 47
    },
    {
      "epoch": 0.17142857142857143,
      "grad_norm": 2.048156261444092,
      "learning_rate": 1.910843373493976e-05,
      "loss": 3.3593,
      "step": 48
    },
    {
      "epoch": 0.175,
      "grad_norm": 1.9334805011749268,
      "learning_rate": 1.908433734939759e-05,
      "loss": 3.1889,
      "step": 49
    },
    {
      "epoch": 0.17857142857142858,
      "grad_norm": 1.7902711629867554,
      "learning_rate": 1.9060240963855423e-05,
      "loss": 3.1023,
      "step": 50
    },
    {
      "epoch": 0.18214285714285713,
      "grad_norm": 2.0465986728668213,
      "learning_rate": 1.9036144578313255e-05,
      "loss": 3.2817,
      "step": 51
    },
    {
      "epoch": 0.18571428571428572,
      "grad_norm": 1.9188201427459717,
      "learning_rate": 1.9012048192771087e-05,
      "loss": 3.1262,
      "step": 52
    },
    {
      "epoch": 0.18928571428571428,
      "grad_norm": 1.8897244930267334,
      "learning_rate": 1.898795180722892e-05,
      "loss": 3.0283,
      "step": 53
    },
    {
      "epoch": 0.19285714285714287,
      "grad_norm": 1.9843276739120483,
      "learning_rate": 1.8963855421686747e-05,
      "loss": 3.039,
      "step": 54
    },
    {
      "epoch": 0.19642857142857142,
      "grad_norm": 2.03045916557312,
      "learning_rate": 1.893975903614458e-05,
      "loss": 3.0167,
      "step": 55
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.0318729877471924,
      "learning_rate": 1.891566265060241e-05,
      "loss": 3.0678,
      "step": 56
    },
    {
      "epoch": 0.20357142857142857,
      "grad_norm": 1.9611940383911133,
      "learning_rate": 1.8891566265060242e-05,
      "loss": 2.976,
      "step": 57
    },
    {
      "epoch": 0.20714285714285716,
      "grad_norm": 1.9360589981079102,
      "learning_rate": 1.8867469879518074e-05,
      "loss": 2.96,
      "step": 58
    },
    {
      "epoch": 0.21071428571428572,
      "grad_norm": 1.9134842157363892,
      "learning_rate": 1.8843373493975906e-05,
      "loss": 2.8603,
      "step": 59
    },
    {
      "epoch": 0.21428571428571427,
      "grad_norm": 1.9793550968170166,
      "learning_rate": 1.8819277108433734e-05,
      "loss": 2.9287,
      "step": 60
    },
    {
      "epoch": 0.21785714285714286,
      "grad_norm": 2.059096097946167,
      "learning_rate": 1.879518072289157e-05,
      "loss": 2.8555,
      "step": 61
    },
    {
      "epoch": 0.22142857142857142,
      "grad_norm": 1.8721405267715454,
      "learning_rate": 1.8771084337349398e-05,
      "loss": 2.8062,
      "step": 62
    },
    {
      "epoch": 0.225,
      "grad_norm": 1.7886502742767334,
      "learning_rate": 1.874698795180723e-05,
      "loss": 2.7272,
      "step": 63
    },
    {
      "epoch": 0.22857142857142856,
      "grad_norm": 1.8401329517364502,
      "learning_rate": 1.872289156626506e-05,
      "loss": 2.7161,
      "step": 64
    },
    {
      "epoch": 0.23214285714285715,
      "grad_norm": 1.8457140922546387,
      "learning_rate": 1.8698795180722893e-05,
      "loss": 2.7607,
      "step": 65
    },
    {
      "epoch": 0.2357142857142857,
      "grad_norm": 1.9569587707519531,
      "learning_rate": 1.8674698795180725e-05,
      "loss": 2.7546,
      "step": 66
    },
    {
      "epoch": 0.2392857142857143,
      "grad_norm": 1.7955771684646606,
      "learning_rate": 1.8650602409638556e-05,
      "loss": 2.6997,
      "step": 67
    },
    {
      "epoch": 0.24285714285714285,
      "grad_norm": 1.732554316520691,
      "learning_rate": 1.8626506024096388e-05,
      "loss": 2.5859,
      "step": 68
    },
    {
      "epoch": 0.24642857142857144,
      "grad_norm": 1.9211989641189575,
      "learning_rate": 1.8602409638554217e-05,
      "loss": 2.7142,
      "step": 69
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.7429627180099487,
      "learning_rate": 1.8578313253012052e-05,
      "loss": 2.4876,
      "step": 70
    },
    {
      "epoch": 0.25357142857142856,
      "grad_norm": 1.7620816230773926,
      "learning_rate": 1.855421686746988e-05,
      "loss": 2.5687,
      "step": 71
    },
    {
      "epoch": 0.2571428571428571,
      "grad_norm": 2.164268970489502,
      "learning_rate": 1.8530120481927712e-05,
      "loss": 2.7445,
      "step": 72
    },
    {
      "epoch": 0.26071428571428573,
      "grad_norm": 1.8384405374526978,
      "learning_rate": 1.8506024096385544e-05,
      "loss": 2.4971,
      "step": 73
    },
    {
      "epoch": 0.2642857142857143,
      "grad_norm": 1.815026044845581,
      "learning_rate": 1.8481927710843375e-05,
      "loss": 2.3951,
      "step": 74
    },
    {
      "epoch": 0.26785714285714285,
      "grad_norm": 1.8641546964645386,
      "learning_rate": 1.8457831325301204e-05,
      "loss": 2.4314,
      "step": 75
    },
    {
      "epoch": 0.2714285714285714,
      "grad_norm": 1.952675461769104,
      "learning_rate": 1.843373493975904e-05,
      "loss": 2.5544,
      "step": 76
    },
    {
      "epoch": 0.275,
      "grad_norm": 1.9751224517822266,
      "learning_rate": 1.8409638554216867e-05,
      "loss": 2.3973,
      "step": 77
    },
    {
      "epoch": 0.2785714285714286,
      "grad_norm": 2.074291229248047,
      "learning_rate": 1.83855421686747e-05,
      "loss": 2.4502,
      "step": 78
    },
    {
      "epoch": 0.28214285714285714,
      "grad_norm": 2.013305187225342,
      "learning_rate": 1.836144578313253e-05,
      "loss": 2.3764,
      "step": 79
    },
    {
      "epoch": 0.2857142857142857,
      "grad_norm": 2.006464719772339,
      "learning_rate": 1.8337349397590363e-05,
      "loss": 2.3239,
      "step": 80
    },
    {
      "epoch": 0.2892857142857143,
      "grad_norm": 1.975691556930542,
      "learning_rate": 1.8313253012048194e-05,
      "loss": 2.1891,
      "step": 81
    },
    {
      "epoch": 0.29285714285714287,
      "grad_norm": 2.0898325443267822,
      "learning_rate": 1.8289156626506026e-05,
      "loss": 2.2363,
      "step": 82
    },
    {
      "epoch": 0.29642857142857143,
      "grad_norm": 2.281416893005371,
      "learning_rate": 1.8265060240963858e-05,
      "loss": 2.1942,
      "step": 83
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.127601146697998,
      "learning_rate": 1.8240963855421686e-05,
      "loss": 2.263,
      "step": 84
    },
    {
      "epoch": 0.30357142857142855,
      "grad_norm": 2.2393994331359863,
      "learning_rate": 1.821686746987952e-05,
      "loss": 2.1872,
      "step": 85
    },
    {
      "epoch": 0.30714285714285716,
      "grad_norm": 2.1931138038635254,
      "learning_rate": 1.819277108433735e-05,
      "loss": 2.1202,
      "step": 86
    },
    {
      "epoch": 0.3107142857142857,
      "grad_norm": 2.129633903503418,
      "learning_rate": 1.816867469879518e-05,
      "loss": 2.0962,
      "step": 87
    },
    {
      "epoch": 0.3142857142857143,
      "grad_norm": 2.090254545211792,
      "learning_rate": 1.8144578313253013e-05,
      "loss": 2.083,
      "step": 88
    },
    {
      "epoch": 0.31785714285714284,
      "grad_norm": 2.2423794269561768,
      "learning_rate": 1.8120481927710845e-05,
      "loss": 2.0047,
      "step": 89
    },
    {
      "epoch": 0.32142857142857145,
      "grad_norm": 2.0850932598114014,
      "learning_rate": 1.8096385542168677e-05,
      "loss": 1.9767,
      "step": 90
    },
    {
      "epoch": 0.325,
      "grad_norm": 1.8836002349853516,
      "learning_rate": 1.807228915662651e-05,
      "loss": 1.86,
      "step": 91
    },
    {
      "epoch": 0.32857142857142857,
      "grad_norm": 2.0327930450439453,
      "learning_rate": 1.8048192771084337e-05,
      "loss": 2.001,
      "step": 92
    },
    {
      "epoch": 0.33214285714285713,
      "grad_norm": 1.924464225769043,
      "learning_rate": 1.802409638554217e-05,
      "loss": 1.8488,
      "step": 93
    },
    {
      "epoch": 0.3357142857142857,
      "grad_norm": 1.8560526371002197,
      "learning_rate": 1.8e-05,
      "loss": 1.9049,
      "step": 94
    },
    {
      "epoch": 0.3392857142857143,
      "grad_norm": 1.7688238620758057,
      "learning_rate": 1.7975903614457832e-05,
      "loss": 1.7707,
      "step": 95
    },
    {
      "epoch": 0.34285714285714286,
      "grad_norm": 1.8896163702011108,
      "learning_rate": 1.7951807228915664e-05,
      "loss": 1.8032,
      "step": 96
    },
    {
      "epoch": 0.3464285714285714,
      "grad_norm": 1.8001446723937988,
      "learning_rate": 1.7927710843373496e-05,
      "loss": 1.7964,
      "step": 97
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.8900786638259888,
      "learning_rate": 1.7903614457831327e-05,
      "loss": 1.7969,
      "step": 98
    },
    {
      "epoch": 0.3535714285714286,
      "grad_norm": 1.8385177850723267,
      "learning_rate": 1.7879518072289156e-05,
      "loss": 1.7695,
      "step": 99
    },
    {
      "epoch": 0.35714285714285715,
      "grad_norm": 1.890625,
      "learning_rate": 1.785542168674699e-05,
      "loss": 1.7036,
      "step": 100
    },
    {
      "epoch": 0.3607142857142857,
      "grad_norm": 1.8775233030319214,
      "learning_rate": 1.783132530120482e-05,
      "loss": 1.6474,
      "step": 101
    },
    {
      "epoch": 0.36428571428571427,
      "grad_norm": 1.8851613998413086,
      "learning_rate": 1.780722891566265e-05,
      "loss": 1.6921,
      "step": 102
    },
    {
      "epoch": 0.3678571428571429,
      "grad_norm": 1.9728379249572754,
      "learning_rate": 1.7783132530120483e-05,
      "loss": 1.6447,
      "step": 103
    },
    {
      "epoch": 0.37142857142857144,
      "grad_norm": 1.870786190032959,
      "learning_rate": 1.7759036144578315e-05,
      "loss": 1.6109,
      "step": 104
    },
    {
      "epoch": 0.375,
      "grad_norm": 1.8838322162628174,
      "learning_rate": 1.7734939759036146e-05,
      "loss": 1.5994,
      "step": 105
    },
    {
      "epoch": 0.37857142857142856,
      "grad_norm": 1.9622297286987305,
      "learning_rate": 1.7710843373493978e-05,
      "loss": 1.5546,
      "step": 106
    },
    {
      "epoch": 0.3821428571428571,
      "grad_norm": 2.005788564682007,
      "learning_rate": 1.768674698795181e-05,
      "loss": 1.6464,
      "step": 107
    },
    {
      "epoch": 0.38571428571428573,
      "grad_norm": 1.8062478303909302,
      "learning_rate": 1.766265060240964e-05,
      "loss": 1.5206,
      "step": 108
    },
    {
      "epoch": 0.3892857142857143,
      "grad_norm": 1.8345874547958374,
      "learning_rate": 1.763855421686747e-05,
      "loss": 1.5111,
      "step": 109
    },
    {
      "epoch": 0.39285714285714285,
      "grad_norm": 1.8258323669433594,
      "learning_rate": 1.7614457831325302e-05,
      "loss": 1.4062,
      "step": 110
    },
    {
      "epoch": 0.3964285714285714,
      "grad_norm": 1.8945640325546265,
      "learning_rate": 1.7590361445783134e-05,
      "loss": 1.4446,
      "step": 111
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.000694513320923,
      "learning_rate": 1.7566265060240965e-05,
      "loss": 1.443,
      "step": 112
    },
    {
      "epoch": 0.4035714285714286,
      "grad_norm": 1.9519555568695068,
      "learning_rate": 1.7542168674698797e-05,
      "loss": 1.3272,
      "step": 113
    },
    {
      "epoch": 0.40714285714285714,
      "grad_norm": 2.088046073913574,
      "learning_rate": 1.7518072289156625e-05,
      "loss": 1.2992,
      "step": 114
    },
    {
      "epoch": 0.4107142857142857,
      "grad_norm": 2.092481851577759,
      "learning_rate": 1.749397590361446e-05,
      "loss": 1.2912,
      "step": 115
    },
    {
      "epoch": 0.4142857142857143,
      "grad_norm": 2.075457811355591,
      "learning_rate": 1.746987951807229e-05,
      "loss": 1.2543,
      "step": 116
    },
    {
      "epoch": 0.41785714285714287,
      "grad_norm": 2.2946720123291016,
      "learning_rate": 1.7445783132530124e-05,
      "loss": 1.2474,
      "step": 117
    },
    {
      "epoch": 0.42142857142857143,
      "grad_norm": 2.158531904220581,
      "learning_rate": 1.7421686746987953e-05,
      "loss": 1.2269,
      "step": 118
    },
    {
      "epoch": 0.425,
      "grad_norm": 2.307044267654419,
      "learning_rate": 1.7397590361445784e-05,
      "loss": 1.245,
      "step": 119
    },
    {
      "epoch": 0.42857142857142855,
      "grad_norm": 2.1518502235412598,
      "learning_rate": 1.7373493975903616e-05,
      "loss": 1.1478,
      "step": 120
    },
    {
      "epoch": 0.43214285714285716,
      "grad_norm": 2.381375312805176,
      "learning_rate": 1.7349397590361448e-05,
      "loss": 1.1759,
      "step": 121
    },
    {
      "epoch": 0.4357142857142857,
      "grad_norm": 2.6364505290985107,
      "learning_rate": 1.732530120481928e-05,
      "loss": 1.197,
      "step": 122
    },
    {
      "epoch": 0.4392857142857143,
      "grad_norm": 2.3618199825286865,
      "learning_rate": 1.730120481927711e-05,
      "loss": 1.1449,
      "step": 123
    },
    {
      "epoch": 0.44285714285714284,
      "grad_norm": 2.5355849266052246,
      "learning_rate": 1.7277108433734943e-05,
      "loss": 1.1575,
      "step": 124
    },
    {
      "epoch": 0.44642857142857145,
      "grad_norm": 3.1072680950164795,
      "learning_rate": 1.725301204819277e-05,
      "loss": 1.1226,
      "step": 125
    },
    {
      "epoch": 0.45,
      "grad_norm": 3.2643802165985107,
      "learning_rate": 1.7228915662650603e-05,
      "loss": 1.1575,
      "step": 126
    },
    {
      "epoch": 0.45357142857142857,
      "grad_norm": 2.9944562911987305,
      "learning_rate": 1.7204819277108435e-05,
      "loss": 1.0501,
      "step": 127
    },
    {
      "epoch": 0.45714285714285713,
      "grad_norm": 3.5879790782928467,
      "learning_rate": 1.7180722891566267e-05,
      "loss": 1.0681,
      "step": 128
    },
    {
      "epoch": 0.4607142857142857,
      "grad_norm": 3.2143406867980957,
      "learning_rate": 1.71566265060241e-05,
      "loss": 1.0566,
      "step": 129
    },
    {
      "epoch": 0.4642857142857143,
      "grad_norm": 3.297520875930786,
      "learning_rate": 1.713253012048193e-05,
      "loss": 0.9982,
      "step": 130
    },
    {
      "epoch": 0.46785714285714286,
      "grad_norm": 3.380012273788452,
      "learning_rate": 1.710843373493976e-05,
      "loss": 0.8513,
      "step": 131
    },
    {
      "epoch": 0.4714285714285714,
      "grad_norm": 3.5004498958587646,
      "learning_rate": 1.7084337349397594e-05,
      "loss": 0.9701,
      "step": 132
    },
    {
      "epoch": 0.475,
      "grad_norm": 3.398834466934204,
      "learning_rate": 1.7060240963855422e-05,
      "loss": 0.8896,
      "step": 133
    },
    {
      "epoch": 0.4785714285714286,
      "grad_norm": 2.536311149597168,
      "learning_rate": 1.7036144578313254e-05,
      "loss": 0.9294,
      "step": 134
    },
    {
      "epoch": 0.48214285714285715,
      "grad_norm": 2.551471471786499,
      "learning_rate": 1.7012048192771086e-05,
      "loss": 0.8537,
      "step": 135
    },
    {
      "epoch": 0.4857142857142857,
      "grad_norm": 2.1202259063720703,
      "learning_rate": 1.6987951807228917e-05,
      "loss": 0.9186,
      "step": 136
    },
    {
      "epoch": 0.48928571428571427,
      "grad_norm": 2.361194133758545,
      "learning_rate": 1.696385542168675e-05,
      "loss": 0.9269,
      "step": 137
    },
    {
      "epoch": 0.4928571428571429,
      "grad_norm": 2.0172808170318604,
      "learning_rate": 1.693975903614458e-05,
      "loss": 0.9212,
      "step": 138
    },
    {
      "epoch": 0.49642857142857144,
      "grad_norm": 1.5350641012191772,
      "learning_rate": 1.6915662650602413e-05,
      "loss": 0.823,
      "step": 139
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.4327404499053955,
      "learning_rate": 1.689156626506024e-05,
      "loss": 0.8043,
      "step": 140
    },
    {
      "epoch": 0.5035714285714286,
      "grad_norm": 1.5267105102539062,
      "learning_rate": 1.6867469879518076e-05,
      "loss": 0.8009,
      "step": 141
    },
    {
      "epoch": 0.5071428571428571,
      "grad_norm": 1.4948630332946777,
      "learning_rate": 1.6843373493975905e-05,
      "loss": 0.8004,
      "step": 142
    },
    {
      "epoch": 0.5107142857142857,
      "grad_norm": 1.6614656448364258,
      "learning_rate": 1.6819277108433736e-05,
      "loss": 0.7974,
      "step": 143
    },
    {
      "epoch": 0.5142857142857142,
      "grad_norm": 1.5509579181671143,
      "learning_rate": 1.6795180722891568e-05,
      "loss": 0.7682,
      "step": 144
    },
    {
      "epoch": 0.5178571428571429,
      "grad_norm": 1.7512389421463013,
      "learning_rate": 1.67710843373494e-05,
      "loss": 0.7844,
      "step": 145
    },
    {
      "epoch": 0.5214285714285715,
      "grad_norm": 1.7587946653366089,
      "learning_rate": 1.6746987951807228e-05,
      "loss": 0.7869,
      "step": 146
    },
    {
      "epoch": 0.525,
      "grad_norm": 1.7757728099822998,
      "learning_rate": 1.6722891566265063e-05,
      "loss": 0.7095,
      "step": 147
    },
    {
      "epoch": 0.5285714285714286,
      "grad_norm": 2.190554141998291,
      "learning_rate": 1.6698795180722892e-05,
      "loss": 0.6238,
      "step": 148
    },
    {
      "epoch": 0.5321428571428571,
      "grad_norm": 1.9274908304214478,
      "learning_rate": 1.6674698795180724e-05,
      "loss": 0.7152,
      "step": 149
    },
    {
      "epoch": 0.5357142857142857,
      "grad_norm": 1.9670509099960327,
      "learning_rate": 1.6650602409638555e-05,
      "loss": 0.7125,
      "step": 150
    },
    {
      "epoch": 0.5392857142857143,
      "grad_norm": 1.7576467990875244,
      "learning_rate": 1.6626506024096387e-05,
      "loss": 0.6305,
      "step": 151
    },
    {
      "epoch": 0.5428571428571428,
      "grad_norm": 2.546538829803467,
      "learning_rate": 1.660240963855422e-05,
      "loss": 0.7013,
      "step": 152
    },
    {
      "epoch": 0.5464285714285714,
      "grad_norm": 1.9533451795578003,
      "learning_rate": 1.657831325301205e-05,
      "loss": 0.6407,
      "step": 153
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.6285016536712646,
      "learning_rate": 1.6554216867469882e-05,
      "loss": 0.5955,
      "step": 154
    },
    {
      "epoch": 0.5535714285714286,
      "grad_norm": 3.046978712081909,
      "learning_rate": 1.653012048192771e-05,
      "loss": 0.6362,
      "step": 155
    },
    {
      "epoch": 0.5571428571428572,
      "grad_norm": 1.884706735610962,
      "learning_rate": 1.6506024096385546e-05,
      "loss": 0.5186,
      "step": 156
    },
    {
      "epoch": 0.5607142857142857,
      "grad_norm": 1.8673489093780518,
      "learning_rate": 1.6481927710843374e-05,
      "loss": 0.6017,
      "step": 157
    },
    {
      "epoch": 0.5642857142857143,
      "grad_norm": 1.4769959449768066,
      "learning_rate": 1.6457831325301206e-05,
      "loss": 0.6116,
      "step": 158
    },
    {
      "epoch": 0.5678571428571428,
      "grad_norm": 1.307189702987671,
      "learning_rate": 1.6433734939759038e-05,
      "loss": 0.5451,
      "step": 159
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 1.886917233467102,
      "learning_rate": 1.640963855421687e-05,
      "loss": 0.6059,
      "step": 160
    },
    {
      "epoch": 0.575,
      "grad_norm": 2.040921449661255,
      "learning_rate": 1.63855421686747e-05,
      "loss": 0.5557,
      "step": 161
    },
    {
      "epoch": 0.5785714285714286,
      "grad_norm": 1.3009649515151978,
      "learning_rate": 1.6361445783132533e-05,
      "loss": 0.5417,
      "step": 162
    },
    {
      "epoch": 0.5821428571428572,
      "grad_norm": 1.9869722127914429,
      "learning_rate": 1.633734939759036e-05,
      "loss": 0.49,
      "step": 163
    },
    {
      "epoch": 0.5857142857142857,
      "grad_norm": 3.1084508895874023,
      "learning_rate": 1.6313253012048193e-05,
      "loss": 0.5229,
      "step": 164
    },
    {
      "epoch": 0.5892857142857143,
      "grad_norm": 1.509081482887268,
      "learning_rate": 1.6289156626506025e-05,
      "loss": 0.5385,
      "step": 165
    },
    {
      "epoch": 0.5928571428571429,
      "grad_norm": 2.156371593475342,
      "learning_rate": 1.6265060240963857e-05,
      "loss": 0.5253,
      "step": 166
    },
    {
      "epoch": 0.5964285714285714,
      "grad_norm": 1.8192522525787354,
      "learning_rate": 1.624096385542169e-05,
      "loss": 0.5182,
      "step": 167
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.628049612045288,
      "learning_rate": 1.621686746987952e-05,
      "loss": 0.5075,
      "step": 168
    },
    {
      "epoch": 0.6035714285714285,
      "grad_norm": 1.1556060314178467,
      "learning_rate": 1.6192771084337352e-05,
      "loss": 0.4877,
      "step": 169
    },
    {
      "epoch": 0.6071428571428571,
      "grad_norm": 1.3304344415664673,
      "learning_rate": 1.616867469879518e-05,
      "loss": 0.5063,
      "step": 170
    },
    {
      "epoch": 0.6107142857142858,
      "grad_norm": 1.6389119625091553,
      "learning_rate": 1.6144578313253015e-05,
      "loss": 0.4779,
      "step": 171
    },
    {
      "epoch": 0.6142857142857143,
      "grad_norm": 4.935943603515625,
      "learning_rate": 1.6120481927710844e-05,
      "loss": 0.539,
      "step": 172
    },
    {
      "epoch": 0.6178571428571429,
      "grad_norm": 1.8521995544433594,
      "learning_rate": 1.6096385542168676e-05,
      "loss": 0.44,
      "step": 173
    },
    {
      "epoch": 0.6214285714285714,
      "grad_norm": 1.5498729944229126,
      "learning_rate": 1.6072289156626507e-05,
      "loss": 0.4789,
      "step": 174
    },
    {
      "epoch": 0.625,
      "grad_norm": 1.6099116802215576,
      "learning_rate": 1.604819277108434e-05,
      "loss": 0.4563,
      "step": 175
    },
    {
      "epoch": 0.6285714285714286,
      "grad_norm": 1.2104287147521973,
      "learning_rate": 1.602409638554217e-05,
      "loss": 0.5012,
      "step": 176
    },
    {
      "epoch": 0.6321428571428571,
      "grad_norm": 2.848482847213745,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.4302,
      "step": 177
    },
    {
      "epoch": 0.6357142857142857,
      "grad_norm": 1.8996837139129639,
      "learning_rate": 1.5975903614457834e-05,
      "loss": 0.5246,
      "step": 178
    },
    {
      "epoch": 0.6392857142857142,
      "grad_norm": 1.8222159147262573,
      "learning_rate": 1.5951807228915663e-05,
      "loss": 0.5045,
      "step": 179
    },
    {
      "epoch": 0.6428571428571429,
      "grad_norm": 1.624201774597168,
      "learning_rate": 1.5927710843373495e-05,
      "loss": 0.4575,
      "step": 180
    },
    {
      "epoch": 0.6464285714285715,
      "grad_norm": 2.5797853469848633,
      "learning_rate": 1.5903614457831326e-05,
      "loss": 0.4227,
      "step": 181
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.081059694290161,
      "learning_rate": 1.5879518072289158e-05,
      "loss": 0.4672,
      "step": 182
    },
    {
      "epoch": 0.6535714285714286,
      "grad_norm": 1.0499690771102905,
      "learning_rate": 1.585542168674699e-05,
      "loss": 0.4209,
      "step": 183
    },
    {
      "epoch": 0.6571428571428571,
      "grad_norm": 1.2750873565673828,
      "learning_rate": 1.583132530120482e-05,
      "loss": 0.4285,
      "step": 184
    },
    {
      "epoch": 0.6607142857142857,
      "grad_norm": 1.5342624187469482,
      "learning_rate": 1.580722891566265e-05,
      "loss": 0.4953,
      "step": 185
    },
    {
      "epoch": 0.6642857142857143,
      "grad_norm": 1.0981463193893433,
      "learning_rate": 1.5783132530120485e-05,
      "loss": 0.3818,
      "step": 186
    },
    {
      "epoch": 0.6678571428571428,
      "grad_norm": 5.615961074829102,
      "learning_rate": 1.5759036144578313e-05,
      "loss": 0.4605,
      "step": 187
    },
    {
      "epoch": 0.6714285714285714,
      "grad_norm": 5.596950054168701,
      "learning_rate": 1.5734939759036145e-05,
      "loss": 0.4195,
      "step": 188
    },
    {
      "epoch": 0.675,
      "grad_norm": 3.9371328353881836,
      "learning_rate": 1.5710843373493977e-05,
      "loss": 0.3986,
      "step": 189
    },
    {
      "epoch": 0.6785714285714286,
      "grad_norm": 4.605801105499268,
      "learning_rate": 1.568674698795181e-05,
      "loss": 0.4488,
      "step": 190
    },
    {
      "epoch": 0.6821428571428572,
      "grad_norm": 2.6569457054138184,
      "learning_rate": 1.566265060240964e-05,
      "loss": 0.403,
      "step": 191
    },
    {
      "epoch": 0.6857142857142857,
      "grad_norm": 2.703089475631714,
      "learning_rate": 1.5638554216867472e-05,
      "loss": 0.3677,
      "step": 192
    },
    {
      "epoch": 0.6892857142857143,
      "grad_norm": 1.173147201538086,
      "learning_rate": 1.5614457831325304e-05,
      "loss": 0.3827,
      "step": 193
    },
    {
      "epoch": 0.6928571428571428,
      "grad_norm": 2.2159297466278076,
      "learning_rate": 1.5590361445783132e-05,
      "loss": 0.4195,
      "step": 194
    },
    {
      "epoch": 0.6964285714285714,
      "grad_norm": 3.6749091148376465,
      "learning_rate": 1.5566265060240968e-05,
      "loss": 0.4461,
      "step": 195
    },
    {
      "epoch": 0.7,
      "grad_norm": 3.1826021671295166,
      "learning_rate": 1.5542168674698796e-05,
      "loss": 0.3849,
      "step": 196
    },
    {
      "epoch": 0.7035714285714286,
      "grad_norm": 5.944183349609375,
      "learning_rate": 1.5518072289156628e-05,
      "loss": 0.505,
      "step": 197
    },
    {
      "epoch": 0.7071428571428572,
      "grad_norm": 4.631973743438721,
      "learning_rate": 1.549397590361446e-05,
      "loss": 0.3987,
      "step": 198
    },
    {
      "epoch": 0.7107142857142857,
      "grad_norm": 3.8134377002716064,
      "learning_rate": 1.546987951807229e-05,
      "loss": 0.3921,
      "step": 199
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 1.6026555299758911,
      "learning_rate": 1.544578313253012e-05,
      "loss": 0.4361,
      "step": 200
    },
    {
      "epoch": 0.7178571428571429,
      "grad_norm": 0.8620299696922302,
      "learning_rate": 1.5421686746987955e-05,
      "loss": 0.3671,
      "step": 201
    },
    {
      "epoch": 0.7214285714285714,
      "grad_norm": 1.7307116985321045,
      "learning_rate": 1.5397590361445783e-05,
      "loss": 0.3874,
      "step": 202
    },
    {
      "epoch": 0.725,
      "grad_norm": 3.916486978530884,
      "learning_rate": 1.5373493975903615e-05,
      "loss": 0.4225,
      "step": 203
    },
    {
      "epoch": 0.7285714285714285,
      "grad_norm": 1.4830005168914795,
      "learning_rate": 1.5349397590361447e-05,
      "loss": 0.4203,
      "step": 204
    },
    {
      "epoch": 0.7321428571428571,
      "grad_norm": 1.066116452217102,
      "learning_rate": 1.532530120481928e-05,
      "loss": 0.336,
      "step": 205
    },
    {
      "epoch": 0.7357142857142858,
      "grad_norm": 1.176344633102417,
      "learning_rate": 1.530120481927711e-05,
      "loss": 0.3605,
      "step": 206
    },
    {
      "epoch": 0.7392857142857143,
      "grad_norm": 1.0813772678375244,
      "learning_rate": 1.5277108433734942e-05,
      "loss": 0.3878,
      "step": 207
    },
    {
      "epoch": 0.7428571428571429,
      "grad_norm": 1.8217997550964355,
      "learning_rate": 1.5253012048192772e-05,
      "loss": 0.3801,
      "step": 208
    },
    {
      "epoch": 0.7464285714285714,
      "grad_norm": 2.447274684906006,
      "learning_rate": 1.5228915662650604e-05,
      "loss": 0.4264,
      "step": 209
    },
    {
      "epoch": 0.75,
      "grad_norm": 3.0809171199798584,
      "learning_rate": 1.5204819277108436e-05,
      "loss": 0.368,
      "step": 210
    },
    {
      "epoch": 0.7535714285714286,
      "grad_norm": 2.726398468017578,
      "learning_rate": 1.5180722891566266e-05,
      "loss": 0.4228,
      "step": 211
    },
    {
      "epoch": 0.7571428571428571,
      "grad_norm": 1.8305870294570923,
      "learning_rate": 1.5156626506024097e-05,
      "loss": 0.4306,
      "step": 212
    },
    {
      "epoch": 0.7607142857142857,
      "grad_norm": 3.102555751800537,
      "learning_rate": 1.5132530120481929e-05,
      "loss": 0.3653,
      "step": 213
    },
    {
      "epoch": 0.7642857142857142,
      "grad_norm": 0.9892749190330505,
      "learning_rate": 1.5108433734939761e-05,
      "loss": 0.35,
      "step": 214
    },
    {
      "epoch": 0.7678571428571429,
      "grad_norm": 1.480575680732727,
      "learning_rate": 1.5084337349397591e-05,
      "loss": 0.3359,
      "step": 215
    },
    {
      "epoch": 0.7714285714285715,
      "grad_norm": 1.8468044996261597,
      "learning_rate": 1.5060240963855424e-05,
      "loss": 0.3195,
      "step": 216
    },
    {
      "epoch": 0.775,
      "grad_norm": 3.1700122356414795,
      "learning_rate": 1.5036144578313254e-05,
      "loss": 0.325,
      "step": 217
    },
    {
      "epoch": 0.7785714285714286,
      "grad_norm": 1.3937649726867676,
      "learning_rate": 1.5012048192771084e-05,
      "loss": 0.3606,
      "step": 218
    },
    {
      "epoch": 0.7821428571428571,
      "grad_norm": 2.0614914894104004,
      "learning_rate": 1.4987951807228918e-05,
      "loss": 0.3593,
      "step": 219
    },
    {
      "epoch": 0.7857142857142857,
      "grad_norm": 2.2568438053131104,
      "learning_rate": 1.4963855421686748e-05,
      "loss": 0.3416,
      "step": 220
    },
    {
      "epoch": 0.7892857142857143,
      "grad_norm": 2.6992931365966797,
      "learning_rate": 1.4939759036144578e-05,
      "loss": 0.3761,
      "step": 221
    },
    {
      "epoch": 0.7928571428571428,
      "grad_norm": 2.7002127170562744,
      "learning_rate": 1.4915662650602412e-05,
      "loss": 0.3817,
      "step": 222
    },
    {
      "epoch": 0.7964285714285714,
      "grad_norm": 4.889570713043213,
      "learning_rate": 1.4891566265060242e-05,
      "loss": 0.3663,
      "step": 223
    },
    {
      "epoch": 0.8,
      "grad_norm": 3.210129499435425,
      "learning_rate": 1.4867469879518073e-05,
      "loss": 0.3951,
      "step": 224
    },
    {
      "epoch": 0.8035714285714286,
      "grad_norm": 3.9780406951904297,
      "learning_rate": 1.4843373493975905e-05,
      "loss": 0.4003,
      "step": 225
    },
    {
      "epoch": 0.8071428571428572,
      "grad_norm": 3.999354124069214,
      "learning_rate": 1.4819277108433737e-05,
      "loss": 0.3492,
      "step": 226
    },
    {
      "epoch": 0.8107142857142857,
      "grad_norm": 2.757584571838379,
      "learning_rate": 1.4795180722891567e-05,
      "loss": 0.3703,
      "step": 227
    },
    {
      "epoch": 0.8142857142857143,
      "grad_norm": 1.5985546112060547,
      "learning_rate": 1.4771084337349399e-05,
      "loss": 0.3257,
      "step": 228
    },
    {
      "epoch": 0.8178571428571428,
      "grad_norm": 1.2419168949127197,
      "learning_rate": 1.474698795180723e-05,
      "loss": 0.3362,
      "step": 229
    },
    {
      "epoch": 0.8214285714285714,
      "grad_norm": 1.3200651407241821,
      "learning_rate": 1.472289156626506e-05,
      "loss": 0.3143,
      "step": 230
    },
    {
      "epoch": 0.825,
      "grad_norm": 1.1444933414459229,
      "learning_rate": 1.4698795180722894e-05,
      "loss": 0.3818,
      "step": 231
    },
    {
      "epoch": 0.8285714285714286,
      "grad_norm": 3.8994662761688232,
      "learning_rate": 1.4674698795180724e-05,
      "loss": 0.3725,
      "step": 232
    },
    {
      "epoch": 0.8321428571428572,
      "grad_norm": 3.4028942584991455,
      "learning_rate": 1.4650602409638554e-05,
      "loss": 0.3561,
      "step": 233
    },
    {
      "epoch": 0.8357142857142857,
      "grad_norm": 2.81632924079895,
      "learning_rate": 1.4626506024096388e-05,
      "loss": 0.3474,
      "step": 234
    },
    {
      "epoch": 0.8392857142857143,
      "grad_norm": 3.7140650749206543,
      "learning_rate": 1.4602409638554218e-05,
      "loss": 0.3591,
      "step": 235
    },
    {
      "epoch": 0.8428571428571429,
      "grad_norm": 2.11686635017395,
      "learning_rate": 1.457831325301205e-05,
      "loss": 0.3494,
      "step": 236
    },
    {
      "epoch": 0.8464285714285714,
      "grad_norm": 1.6783446073532104,
      "learning_rate": 1.4554216867469881e-05,
      "loss": 0.346,
      "step": 237
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.894811987876892,
      "learning_rate": 1.4530120481927711e-05,
      "loss": 0.3715,
      "step": 238
    },
    {
      "epoch": 0.8535714285714285,
      "grad_norm": 1.7155996561050415,
      "learning_rate": 1.4506024096385543e-05,
      "loss": 0.3367,
      "step": 239
    },
    {
      "epoch": 0.8571428571428571,
      "grad_norm": 2.276369571685791,
      "learning_rate": 1.4481927710843375e-05,
      "loss": 0.2909,
      "step": 240
    },
    {
      "epoch": 0.8607142857142858,
      "grad_norm": 2.275240421295166,
      "learning_rate": 1.4457831325301207e-05,
      "loss": 0.3793,
      "step": 241
    },
    {
      "epoch": 0.8642857142857143,
      "grad_norm": 2.805100202560425,
      "learning_rate": 1.4433734939759037e-05,
      "loss": 0.3209,
      "step": 242
    },
    {
      "epoch": 0.8678571428571429,
      "grad_norm": 1.0745285749435425,
      "learning_rate": 1.440963855421687e-05,
      "loss": 0.339,
      "step": 243
    },
    {
      "epoch": 0.8714285714285714,
      "grad_norm": 3.0439772605895996,
      "learning_rate": 1.43855421686747e-05,
      "loss": 0.3802,
      "step": 244
    },
    {
      "epoch": 0.875,
      "grad_norm": 1.5460296869277954,
      "learning_rate": 1.436144578313253e-05,
      "loss": 0.3462,
      "step": 245
    },
    {
      "epoch": 0.8785714285714286,
      "grad_norm": 2.576539993286133,
      "learning_rate": 1.4337349397590364e-05,
      "loss": 0.3253,
      "step": 246
    },
    {
      "epoch": 0.8821428571428571,
      "grad_norm": 1.612960934638977,
      "learning_rate": 1.4313253012048194e-05,
      "loss": 0.348,
      "step": 247
    },
    {
      "epoch": 0.8857142857142857,
      "grad_norm": 1.0210144519805908,
      "learning_rate": 1.4289156626506024e-05,
      "loss": 0.2982,
      "step": 248
    },
    {
      "epoch": 0.8892857142857142,
      "grad_norm": 1.1562252044677734,
      "learning_rate": 1.4265060240963857e-05,
      "loss": 0.3496,
      "step": 249
    },
    {
      "epoch": 0.8928571428571429,
      "grad_norm": 1.114742636680603,
      "learning_rate": 1.4240963855421687e-05,
      "loss": 0.3777,
      "step": 250
    },
    {
      "epoch": 0.8964285714285715,
      "grad_norm": 2.334019422531128,
      "learning_rate": 1.4216867469879519e-05,
      "loss": 0.3382,
      "step": 251
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.6073774099349976,
      "learning_rate": 1.419277108433735e-05,
      "loss": 0.3069,
      "step": 252
    },
    {
      "epoch": 0.9035714285714286,
      "grad_norm": 3.0912842750549316,
      "learning_rate": 1.4168674698795183e-05,
      "loss": 0.3008,
      "step": 253
    },
    {
      "epoch": 0.9071428571428571,
      "grad_norm": 3.9315099716186523,
      "learning_rate": 1.4144578313253013e-05,
      "loss": 0.3021,
      "step": 254
    },
    {
      "epoch": 0.9107142857142857,
      "grad_norm": 2.904278039932251,
      "learning_rate": 1.4120481927710844e-05,
      "loss": 0.3601,
      "step": 255
    },
    {
      "epoch": 0.9142857142857143,
      "grad_norm": 2.2334859371185303,
      "learning_rate": 1.4096385542168676e-05,
      "loss": 0.3328,
      "step": 256
    },
    {
      "epoch": 0.9178571428571428,
      "grad_norm": 1.425855278968811,
      "learning_rate": 1.4072289156626506e-05,
      "loss": 0.3144,
      "step": 257
    },
    {
      "epoch": 0.9214285714285714,
      "grad_norm": 1.8865859508514404,
      "learning_rate": 1.404819277108434e-05,
      "loss": 0.2933,
      "step": 258
    },
    {
      "epoch": 0.925,
      "grad_norm": 1.1652607917785645,
      "learning_rate": 1.402409638554217e-05,
      "loss": 0.3179,
      "step": 259
    },
    {
      "epoch": 0.9285714285714286,
      "grad_norm": 1.7583870887756348,
      "learning_rate": 1.4e-05,
      "loss": 0.3096,
      "step": 260
    },
    {
      "epoch": 0.9321428571428572,
      "grad_norm": 1.1531463861465454,
      "learning_rate": 1.3975903614457833e-05,
      "loss": 0.3047,
      "step": 261
    },
    {
      "epoch": 0.9357142857142857,
      "grad_norm": 1.2125962972640991,
      "learning_rate": 1.3951807228915663e-05,
      "loss": 0.3582,
      "step": 262
    },
    {
      "epoch": 0.9392857142857143,
      "grad_norm": 1.4151512384414673,
      "learning_rate": 1.3927710843373493e-05,
      "loss": 0.3065,
      "step": 263
    },
    {
      "epoch": 0.9428571428571428,
      "grad_norm": 1.1968249082565308,
      "learning_rate": 1.3903614457831327e-05,
      "loss": 0.3102,
      "step": 264
    },
    {
      "epoch": 0.9464285714285714,
      "grad_norm": 1.2205164432525635,
      "learning_rate": 1.3879518072289157e-05,
      "loss": 0.3157,
      "step": 265
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.9831995964050293,
      "learning_rate": 1.3855421686746989e-05,
      "loss": 0.3001,
      "step": 266
    },
    {
      "epoch": 0.9535714285714286,
      "grad_norm": 1.4910862445831299,
      "learning_rate": 1.383132530120482e-05,
      "loss": 0.2702,
      "step": 267
    },
    {
      "epoch": 0.9571428571428572,
      "grad_norm": 1.4380906820297241,
      "learning_rate": 1.3807228915662652e-05,
      "loss": 0.3424,
      "step": 268
    },
    {
      "epoch": 0.9607142857142857,
      "grad_norm": 1.6458481550216675,
      "learning_rate": 1.3783132530120482e-05,
      "loss": 0.3209,
      "step": 269
    },
    {
      "epoch": 0.9642857142857143,
      "grad_norm": 1.1468002796173096,
      "learning_rate": 1.3759036144578316e-05,
      "loss": 0.2976,
      "step": 270
    },
    {
      "epoch": 0.9678571428571429,
      "grad_norm": 1.4933462142944336,
      "learning_rate": 1.3734939759036146e-05,
      "loss": 0.3102,
      "step": 271
    },
    {
      "epoch": 0.9714285714285714,
      "grad_norm": 1.5345256328582764,
      "learning_rate": 1.3710843373493976e-05,
      "loss": 0.3241,
      "step": 272
    },
    {
      "epoch": 0.975,
      "grad_norm": 1.9793965816497803,
      "learning_rate": 1.368674698795181e-05,
      "loss": 0.3273,
      "step": 273
    },
    {
      "epoch": 0.9785714285714285,
      "grad_norm": 1.754056453704834,
      "learning_rate": 1.366265060240964e-05,
      "loss": 0.4115,
      "step": 274
    },
    {
      "epoch": 0.9821428571428571,
      "grad_norm": 1.9530214071273804,
      "learning_rate": 1.363855421686747e-05,
      "loss": 0.3222,
      "step": 275
    },
    {
      "epoch": 0.9857142857142858,
      "grad_norm": 1.676355242729187,
      "learning_rate": 1.3614457831325303e-05,
      "loss": 0.345,
      "step": 276
    },
    {
      "epoch": 0.9892857142857143,
      "grad_norm": 1.5954816341400146,
      "learning_rate": 1.3590361445783133e-05,
      "loss": 0.2977,
      "step": 277
    },
    {
      "epoch": 0.9928571428571429,
      "grad_norm": 1.9800187349319458,
      "learning_rate": 1.3566265060240965e-05,
      "loss": 0.286,
      "step": 278
    },
    {
      "epoch": 0.9964285714285714,
      "grad_norm": 2.370570421218872,
      "learning_rate": 1.3542168674698796e-05,
      "loss": 0.3219,
      "step": 279
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.7688748836517334,
      "learning_rate": 1.3518072289156628e-05,
      "loss": 0.2798,
      "step": 280
    },
    {
      "epoch": 1.0035714285714286,
      "grad_norm": 1.507617473602295,
      "learning_rate": 1.3493975903614458e-05,
      "loss": 0.3239,
      "step": 281
    },
    {
      "epoch": 1.0071428571428571,
      "grad_norm": 1.5273293256759644,
      "learning_rate": 1.346987951807229e-05,
      "loss": 0.3462,
      "step": 282
    },
    {
      "epoch": 1.0107142857142857,
      "grad_norm": 1.3374272584915161,
      "learning_rate": 1.3445783132530122e-05,
      "loss": 0.3332,
      "step": 283
    },
    {
      "epoch": 1.0142857142857142,
      "grad_norm": 2.02388858795166,
      "learning_rate": 1.3421686746987952e-05,
      "loss": 0.3014,
      "step": 284
    },
    {
      "epoch": 1.0178571428571428,
      "grad_norm": 1.0786129236221313,
      "learning_rate": 1.3397590361445785e-05,
      "loss": 0.2963,
      "step": 285
    },
    {
      "epoch": 1.0214285714285714,
      "grad_norm": 1.1921913623809814,
      "learning_rate": 1.3373493975903615e-05,
      "loss": 0.3221,
      "step": 286
    },
    {
      "epoch": 1.025,
      "grad_norm": 1.1442699432373047,
      "learning_rate": 1.3349397590361445e-05,
      "loss": 0.3035,
      "step": 287
    },
    {
      "epoch": 1.0285714285714285,
      "grad_norm": 4.36400032043457,
      "learning_rate": 1.3325301204819279e-05,
      "loss": 0.3129,
      "step": 288
    },
    {
      "epoch": 1.032142857142857,
      "grad_norm": 1.9183695316314697,
      "learning_rate": 1.3301204819277109e-05,
      "loss": 0.2759,
      "step": 289
    },
    {
      "epoch": 1.0357142857142858,
      "grad_norm": 2.0473508834838867,
      "learning_rate": 1.3277108433734939e-05,
      "loss": 0.3096,
      "step": 290
    },
    {
      "epoch": 1.0392857142857144,
      "grad_norm": 1.7393993139266968,
      "learning_rate": 1.3253012048192772e-05,
      "loss": 0.3363,
      "step": 291
    },
    {
      "epoch": 1.042857142857143,
      "grad_norm": 1.8399361371994019,
      "learning_rate": 1.3228915662650603e-05,
      "loss": 0.3372,
      "step": 292
    },
    {
      "epoch": 1.0464285714285715,
      "grad_norm": 1.0750573873519897,
      "learning_rate": 1.3204819277108434e-05,
      "loss": 0.3463,
      "step": 293
    },
    {
      "epoch": 1.05,
      "grad_norm": 2.742542028427124,
      "learning_rate": 1.3180722891566266e-05,
      "loss": 0.3131,
      "step": 294
    },
    {
      "epoch": 1.0535714285714286,
      "grad_norm": 0.9834339022636414,
      "learning_rate": 1.3156626506024098e-05,
      "loss": 0.3268,
      "step": 295
    },
    {
      "epoch": 1.0571428571428572,
      "grad_norm": 1.4122047424316406,
      "learning_rate": 1.3132530120481928e-05,
      "loss": 0.2716,
      "step": 296
    },
    {
      "epoch": 1.0607142857142857,
      "grad_norm": 1.9208580255508423,
      "learning_rate": 1.3108433734939761e-05,
      "loss": 0.301,
      "step": 297
    },
    {
      "epoch": 1.0642857142857143,
      "grad_norm": 1.5650415420532227,
      "learning_rate": 1.3084337349397591e-05,
      "loss": 0.2928,
      "step": 298
    },
    {
      "epoch": 1.0678571428571428,
      "grad_norm": 1.4414336681365967,
      "learning_rate": 1.3060240963855421e-05,
      "loss": 0.2797,
      "step": 299
    },
    {
      "epoch": 1.0714285714285714,
      "grad_norm": 1.8745311498641968,
      "learning_rate": 1.3036144578313255e-05,
      "loss": 0.3191,
      "step": 300
    },
    {
      "epoch": 1.075,
      "grad_norm": 1.9457451105117798,
      "learning_rate": 1.3012048192771085e-05,
      "loss": 0.3159,
      "step": 301
    },
    {
      "epoch": 1.0785714285714285,
      "grad_norm": 1.7586678266525269,
      "learning_rate": 1.2987951807228915e-05,
      "loss": 0.3225,
      "step": 302
    },
    {
      "epoch": 1.082142857142857,
      "grad_norm": 1.7092841863632202,
      "learning_rate": 1.2963855421686749e-05,
      "loss": 0.3057,
      "step": 303
    },
    {
      "epoch": 1.0857142857142856,
      "grad_norm": 2.3301475048065186,
      "learning_rate": 1.2939759036144579e-05,
      "loss": 0.326,
      "step": 304
    },
    {
      "epoch": 1.0892857142857142,
      "grad_norm": 2.839344024658203,
      "learning_rate": 1.291566265060241e-05,
      "loss": 0.3179,
      "step": 305
    },
    {
      "epoch": 1.092857142857143,
      "grad_norm": 2.8650660514831543,
      "learning_rate": 1.2891566265060242e-05,
      "loss": 0.3256,
      "step": 306
    },
    {
      "epoch": 1.0964285714285715,
      "grad_norm": 2.5628750324249268,
      "learning_rate": 1.2867469879518072e-05,
      "loss": 0.2987,
      "step": 307
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.3411316871643066,
      "learning_rate": 1.2843373493975904e-05,
      "loss": 0.298,
      "step": 308
    },
    {
      "epoch": 1.1035714285714286,
      "grad_norm": 2.933969020843506,
      "learning_rate": 1.2819277108433736e-05,
      "loss": 0.3192,
      "step": 309
    },
    {
      "epoch": 1.1071428571428572,
      "grad_norm": 1.9246708154678345,
      "learning_rate": 1.2795180722891567e-05,
      "loss": 0.2975,
      "step": 310
    },
    {
      "epoch": 1.1107142857142858,
      "grad_norm": 1.1955300569534302,
      "learning_rate": 1.2771084337349398e-05,
      "loss": 0.3083,
      "step": 311
    },
    {
      "epoch": 1.1142857142857143,
      "grad_norm": 1.3425451517105103,
      "learning_rate": 1.2746987951807231e-05,
      "loss": 0.3035,
      "step": 312
    },
    {
      "epoch": 1.1178571428571429,
      "grad_norm": 1.3573477268218994,
      "learning_rate": 1.2722891566265061e-05,
      "loss": 0.3423,
      "step": 313
    },
    {
      "epoch": 1.1214285714285714,
      "grad_norm": 1.0564128160476685,
      "learning_rate": 1.2698795180722891e-05,
      "loss": 0.2883,
      "step": 314
    },
    {
      "epoch": 1.125,
      "grad_norm": 1.5249059200286865,
      "learning_rate": 1.2674698795180725e-05,
      "loss": 0.3017,
      "step": 315
    },
    {
      "epoch": 1.1285714285714286,
      "grad_norm": 1.945098876953125,
      "learning_rate": 1.2650602409638555e-05,
      "loss": 0.3475,
      "step": 316
    },
    {
      "epoch": 1.1321428571428571,
      "grad_norm": 2.0103390216827393,
      "learning_rate": 1.2626506024096385e-05,
      "loss": 0.3127,
      "step": 317
    },
    {
      "epoch": 1.1357142857142857,
      "grad_norm": 1.793906331062317,
      "learning_rate": 1.2602409638554218e-05,
      "loss": 0.316,
      "step": 318
    },
    {
      "epoch": 1.1392857142857142,
      "grad_norm": 1.9549171924591064,
      "learning_rate": 1.2578313253012048e-05,
      "loss": 0.2827,
      "step": 319
    },
    {
      "epoch": 1.1428571428571428,
      "grad_norm": 1.8744229078292847,
      "learning_rate": 1.255421686746988e-05,
      "loss": 0.3115,
      "step": 320
    },
    {
      "epoch": 1.1464285714285714,
      "grad_norm": 2.1277713775634766,
      "learning_rate": 1.2530120481927712e-05,
      "loss": 0.2994,
      "step": 321
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.582990288734436,
      "learning_rate": 1.2506024096385544e-05,
      "loss": 0.2969,
      "step": 322
    },
    {
      "epoch": 1.1535714285714285,
      "grad_norm": 1.7626794576644897,
      "learning_rate": 1.2481927710843375e-05,
      "loss": 0.2975,
      "step": 323
    },
    {
      "epoch": 1.157142857142857,
      "grad_norm": 1.1044483184814453,
      "learning_rate": 1.2457831325301207e-05,
      "loss": 0.297,
      "step": 324
    },
    {
      "epoch": 1.1607142857142858,
      "grad_norm": 1.9239771366119385,
      "learning_rate": 1.2433734939759037e-05,
      "loss": 0.2971,
      "step": 325
    },
    {
      "epoch": 1.1642857142857144,
      "grad_norm": 1.5448077917099,
      "learning_rate": 1.2409638554216869e-05,
      "loss": 0.3108,
      "step": 326
    },
    {
      "epoch": 1.167857142857143,
      "grad_norm": 1.674521803855896,
      "learning_rate": 1.23855421686747e-05,
      "loss": 0.32,
      "step": 327
    },
    {
      "epoch": 1.1714285714285715,
      "grad_norm": 1.4433363676071167,
      "learning_rate": 1.236144578313253e-05,
      "loss": 0.35,
      "step": 328
    },
    {
      "epoch": 1.175,
      "grad_norm": 1.5754101276397705,
      "learning_rate": 1.2337349397590364e-05,
      "loss": 0.3315,
      "step": 329
    },
    {
      "epoch": 1.1785714285714286,
      "grad_norm": 1.6872808933258057,
      "learning_rate": 1.2313253012048194e-05,
      "loss": 0.3082,
      "step": 330
    },
    {
      "epoch": 1.1821428571428572,
      "grad_norm": 1.2719186544418335,
      "learning_rate": 1.2289156626506024e-05,
      "loss": 0.2888,
      "step": 331
    },
    {
      "epoch": 1.1857142857142857,
      "grad_norm": 1.5481972694396973,
      "learning_rate": 1.2265060240963858e-05,
      "loss": 0.2624,
      "step": 332
    },
    {
      "epoch": 1.1892857142857143,
      "grad_norm": 2.1629765033721924,
      "learning_rate": 1.2240963855421688e-05,
      "loss": 0.2982,
      "step": 333
    },
    {
      "epoch": 1.1928571428571428,
      "grad_norm": 1.346741795539856,
      "learning_rate": 1.2216867469879518e-05,
      "loss": 0.2832,
      "step": 334
    },
    {
      "epoch": 1.1964285714285714,
      "grad_norm": 2.387315034866333,
      "learning_rate": 1.2192771084337351e-05,
      "loss": 0.286,
      "step": 335
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.8335158824920654,
      "learning_rate": 1.2168674698795181e-05,
      "loss": 0.3102,
      "step": 336
    },
    {
      "epoch": 1.2035714285714285,
      "grad_norm": 2.1959831714630127,
      "learning_rate": 1.2144578313253013e-05,
      "loss": 0.3038,
      "step": 337
    },
    {
      "epoch": 1.207142857142857,
      "grad_norm": 1.344114065170288,
      "learning_rate": 1.2120481927710845e-05,
      "loss": 0.3309,
      "step": 338
    },
    {
      "epoch": 1.2107142857142856,
      "grad_norm": 1.5020033121109009,
      "learning_rate": 1.2096385542168677e-05,
      "loss": 0.2675,
      "step": 339
    },
    {
      "epoch": 1.2142857142857142,
      "grad_norm": 1.2073153257369995,
      "learning_rate": 1.2072289156626507e-05,
      "loss": 0.3153,
      "step": 340
    },
    {
      "epoch": 1.217857142857143,
      "grad_norm": 1.518156886100769,
      "learning_rate": 1.204819277108434e-05,
      "loss": 0.2997,
      "step": 341
    },
    {
      "epoch": 1.2214285714285715,
      "grad_norm": 2.1314547061920166,
      "learning_rate": 1.202409638554217e-05,
      "loss": 0.2622,
      "step": 342
    },
    {
      "epoch": 1.225,
      "grad_norm": 1.0841559171676636,
      "learning_rate": 1.2e-05,
      "loss": 0.2438,
      "step": 343
    },
    {
      "epoch": 1.2285714285714286,
      "grad_norm": 1.3068217039108276,
      "learning_rate": 1.1975903614457834e-05,
      "loss": 0.2596,
      "step": 344
    },
    {
      "epoch": 1.2321428571428572,
      "grad_norm": 1.2023074626922607,
      "learning_rate": 1.1951807228915664e-05,
      "loss": 0.2919,
      "step": 345
    },
    {
      "epoch": 1.2357142857142858,
      "grad_norm": 1.1772493124008179,
      "learning_rate": 1.1927710843373494e-05,
      "loss": 0.3109,
      "step": 346
    },
    {
      "epoch": 1.2392857142857143,
      "grad_norm": 1.9489624500274658,
      "learning_rate": 1.1903614457831327e-05,
      "loss": 0.2999,
      "step": 347
    },
    {
      "epoch": 1.2428571428571429,
      "grad_norm": 1.1158499717712402,
      "learning_rate": 1.1879518072289157e-05,
      "loss": 0.31,
      "step": 348
    },
    {
      "epoch": 1.2464285714285714,
      "grad_norm": 1.3794071674346924,
      "learning_rate": 1.185542168674699e-05,
      "loss": 0.2738,
      "step": 349
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.6034797430038452,
      "learning_rate": 1.1831325301204821e-05,
      "loss": 0.2986,
      "step": 350
    },
    {
      "epoch": 1.2535714285714286,
      "grad_norm": 1.092428207397461,
      "learning_rate": 1.1807228915662651e-05,
      "loss": 0.2918,
      "step": 351
    },
    {
      "epoch": 1.2571428571428571,
      "grad_norm": 1.003210425376892,
      "learning_rate": 1.1783132530120483e-05,
      "loss": 0.2849,
      "step": 352
    },
    {
      "epoch": 1.2607142857142857,
      "grad_norm": 1.5794416666030884,
      "learning_rate": 1.1759036144578315e-05,
      "loss": 0.2994,
      "step": 353
    },
    {
      "epoch": 1.2642857142857142,
      "grad_norm": 0.8834483623504639,
      "learning_rate": 1.1734939759036146e-05,
      "loss": 0.241,
      "step": 354
    },
    {
      "epoch": 1.2678571428571428,
      "grad_norm": 1.6524852514266968,
      "learning_rate": 1.1710843373493976e-05,
      "loss": 0.3238,
      "step": 355
    },
    {
      "epoch": 1.2714285714285714,
      "grad_norm": 2.081874370574951,
      "learning_rate": 1.168674698795181e-05,
      "loss": 0.291,
      "step": 356
    },
    {
      "epoch": 1.275,
      "grad_norm": 1.0716215372085571,
      "learning_rate": 1.166265060240964e-05,
      "loss": 0.2944,
      "step": 357
    },
    {
      "epoch": 1.2785714285714285,
      "grad_norm": 1.0731388330459595,
      "learning_rate": 1.163855421686747e-05,
      "loss": 0.3058,
      "step": 358
    },
    {
      "epoch": 1.282142857142857,
      "grad_norm": 1.4071693420410156,
      "learning_rate": 1.1614457831325303e-05,
      "loss": 0.2745,
      "step": 359
    },
    {
      "epoch": 1.2857142857142856,
      "grad_norm": 1.6053861379623413,
      "learning_rate": 1.1590361445783133e-05,
      "loss": 0.2928,
      "step": 360
    },
    {
      "epoch": 1.2892857142857144,
      "grad_norm": 1.3316789865493774,
      "learning_rate": 1.1566265060240964e-05,
      "loss": 0.2656,
      "step": 361
    },
    {
      "epoch": 1.292857142857143,
      "grad_norm": 1.1703318357467651,
      "learning_rate": 1.1542168674698797e-05,
      "loss": 0.2912,
      "step": 362
    },
    {
      "epoch": 1.2964285714285715,
      "grad_norm": 1.4653263092041016,
      "learning_rate": 1.1518072289156627e-05,
      "loss": 0.3293,
      "step": 363
    },
    {
      "epoch": 1.3,
      "grad_norm": 2.0426769256591797,
      "learning_rate": 1.1493975903614459e-05,
      "loss": 0.2817,
      "step": 364
    },
    {
      "epoch": 1.3035714285714286,
      "grad_norm": 1.3203608989715576,
      "learning_rate": 1.146987951807229e-05,
      "loss": 0.2369,
      "step": 365
    },
    {
      "epoch": 1.3071428571428572,
      "grad_norm": 1.33832585811615,
      "learning_rate": 1.1445783132530122e-05,
      "loss": 0.2587,
      "step": 366
    },
    {
      "epoch": 1.3107142857142857,
      "grad_norm": 1.2061790227890015,
      "learning_rate": 1.1421686746987952e-05,
      "loss": 0.2671,
      "step": 367
    },
    {
      "epoch": 1.3142857142857143,
      "grad_norm": 1.4889860153198242,
      "learning_rate": 1.1397590361445786e-05,
      "loss": 0.245,
      "step": 368
    },
    {
      "epoch": 1.3178571428571428,
      "grad_norm": 1.4829649925231934,
      "learning_rate": 1.1373493975903616e-05,
      "loss": 0.302,
      "step": 369
    },
    {
      "epoch": 1.3214285714285714,
      "grad_norm": 1.551573395729065,
      "learning_rate": 1.1349397590361446e-05,
      "loss": 0.2866,
      "step": 370
    },
    {
      "epoch": 1.325,
      "grad_norm": 1.3428757190704346,
      "learning_rate": 1.132530120481928e-05,
      "loss": 0.2648,
      "step": 371
    },
    {
      "epoch": 1.3285714285714285,
      "grad_norm": 1.9208883047103882,
      "learning_rate": 1.130120481927711e-05,
      "loss": 0.3123,
      "step": 372
    },
    {
      "epoch": 1.332142857142857,
      "grad_norm": 1.7333784103393555,
      "learning_rate": 1.127710843373494e-05,
      "loss": 0.2733,
      "step": 373
    },
    {
      "epoch": 1.3357142857142856,
      "grad_norm": 1.7052737474441528,
      "learning_rate": 1.1253012048192773e-05,
      "loss": 0.2829,
      "step": 374
    },
    {
      "epoch": 1.3392857142857144,
      "grad_norm": 1.3790944814682007,
      "learning_rate": 1.1228915662650603e-05,
      "loss": 0.2823,
      "step": 375
    },
    {
      "epoch": 1.342857142857143,
      "grad_norm": 1.6750000715255737,
      "learning_rate": 1.1204819277108435e-05,
      "loss": 0.2414,
      "step": 376
    },
    {
      "epoch": 1.3464285714285715,
      "grad_norm": 1.5363088846206665,
      "learning_rate": 1.1180722891566267e-05,
      "loss": 0.2421,
      "step": 377
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.4234182834625244,
      "learning_rate": 1.1156626506024097e-05,
      "loss": 0.3136,
      "step": 378
    },
    {
      "epoch": 1.3535714285714286,
      "grad_norm": 1.2512552738189697,
      "learning_rate": 1.1132530120481928e-05,
      "loss": 0.2668,
      "step": 379
    },
    {
      "epoch": 1.3571428571428572,
      "grad_norm": 1.2510210275650024,
      "learning_rate": 1.110843373493976e-05,
      "loss": 0.2859,
      "step": 380
    },
    {
      "epoch": 1.3607142857142858,
      "grad_norm": 1.512261152267456,
      "learning_rate": 1.1084337349397592e-05,
      "loss": 0.2603,
      "step": 381
    },
    {
      "epoch": 1.3642857142857143,
      "grad_norm": 1.410024642944336,
      "learning_rate": 1.1060240963855422e-05,
      "loss": 0.2402,
      "step": 382
    },
    {
      "epoch": 1.3678571428571429,
      "grad_norm": 1.2881782054901123,
      "learning_rate": 1.1036144578313255e-05,
      "loss": 0.2778,
      "step": 383
    },
    {
      "epoch": 1.3714285714285714,
      "grad_norm": 1.175363302230835,
      "learning_rate": 1.1012048192771086e-05,
      "loss": 0.2257,
      "step": 384
    },
    {
      "epoch": 1.375,
      "grad_norm": 1.9726470708847046,
      "learning_rate": 1.0987951807228916e-05,
      "loss": 0.3361,
      "step": 385
    },
    {
      "epoch": 1.3785714285714286,
      "grad_norm": 1.394636631011963,
      "learning_rate": 1.0963855421686749e-05,
      "loss": 0.2928,
      "step": 386
    },
    {
      "epoch": 1.3821428571428571,
      "grad_norm": 1.6214240789413452,
      "learning_rate": 1.0939759036144579e-05,
      "loss": 0.2613,
      "step": 387
    },
    {
      "epoch": 1.3857142857142857,
      "grad_norm": 1.5937637090682983,
      "learning_rate": 1.091566265060241e-05,
      "loss": 0.2879,
      "step": 388
    },
    {
      "epoch": 1.3892857142857142,
      "grad_norm": 1.6380283832550049,
      "learning_rate": 1.0891566265060243e-05,
      "loss": 0.2854,
      "step": 389
    },
    {
      "epoch": 1.3928571428571428,
      "grad_norm": 1.6709977388381958,
      "learning_rate": 1.0867469879518073e-05,
      "loss": 0.2681,
      "step": 390
    },
    {
      "epoch": 1.3964285714285714,
      "grad_norm": 1.5824106931686401,
      "learning_rate": 1.0843373493975904e-05,
      "loss": 0.2796,
      "step": 391
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.9988670349121094,
      "learning_rate": 1.0819277108433736e-05,
      "loss": 0.2749,
      "step": 392
    },
    {
      "epoch": 1.4035714285714285,
      "grad_norm": 1.6098111867904663,
      "learning_rate": 1.0795180722891568e-05,
      "loss": 0.2779,
      "step": 393
    },
    {
      "epoch": 1.407142857142857,
      "grad_norm": 1.9573938846588135,
      "learning_rate": 1.0771084337349398e-05,
      "loss": 0.2638,
      "step": 394
    },
    {
      "epoch": 1.4107142857142856,
      "grad_norm": 1.679970622062683,
      "learning_rate": 1.074698795180723e-05,
      "loss": 0.2434,
      "step": 395
    },
    {
      "epoch": 1.4142857142857144,
      "grad_norm": 1.2414309978485107,
      "learning_rate": 1.0722891566265062e-05,
      "loss": 0.256,
      "step": 396
    },
    {
      "epoch": 1.417857142857143,
      "grad_norm": 1.3082072734832764,
      "learning_rate": 1.0698795180722892e-05,
      "loss": 0.2383,
      "step": 397
    },
    {
      "epoch": 1.4214285714285715,
      "grad_norm": 1.7006233930587769,
      "learning_rate": 1.0674698795180725e-05,
      "loss": 0.2332,
      "step": 398
    },
    {
      "epoch": 1.425,
      "grad_norm": 1.5384784936904907,
      "learning_rate": 1.0650602409638555e-05,
      "loss": 0.2467,
      "step": 399
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 1.5130534172058105,
      "learning_rate": 1.0626506024096385e-05,
      "loss": 0.3158,
      "step": 400
    },
    {
      "epoch": 1.4321428571428572,
      "grad_norm": 1.7106226682662964,
      "learning_rate": 1.0602409638554219e-05,
      "loss": 0.2606,
      "step": 401
    },
    {
      "epoch": 1.4357142857142857,
      "grad_norm": 1.4882787466049194,
      "learning_rate": 1.0578313253012049e-05,
      "loss": 0.2435,
      "step": 402
    },
    {
      "epoch": 1.4392857142857143,
      "grad_norm": 2.119323253631592,
      "learning_rate": 1.055421686746988e-05,
      "loss": 0.2369,
      "step": 403
    },
    {
      "epoch": 1.4428571428571428,
      "grad_norm": 1.6569114923477173,
      "learning_rate": 1.0530120481927712e-05,
      "loss": 0.2447,
      "step": 404
    },
    {
      "epoch": 1.4464285714285714,
      "grad_norm": 2.14570689201355,
      "learning_rate": 1.0506024096385542e-05,
      "loss": 0.3113,
      "step": 405
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.708169937133789,
      "learning_rate": 1.0481927710843374e-05,
      "loss": 0.3033,
      "step": 406
    },
    {
      "epoch": 1.4535714285714285,
      "grad_norm": 1.2456202507019043,
      "learning_rate": 1.0457831325301206e-05,
      "loss": 0.2504,
      "step": 407
    },
    {
      "epoch": 1.457142857142857,
      "grad_norm": 1.2910901308059692,
      "learning_rate": 1.0433734939759038e-05,
      "loss": 0.2428,
      "step": 408
    },
    {
      "epoch": 1.4607142857142856,
      "grad_norm": 1.7686883211135864,
      "learning_rate": 1.0409638554216868e-05,
      "loss": 0.2539,
      "step": 409
    },
    {
      "epoch": 1.4642857142857144,
      "grad_norm": 1.1127279996871948,
      "learning_rate": 1.0385542168674701e-05,
      "loss": 0.2322,
      "step": 410
    },
    {
      "epoch": 1.467857142857143,
      "grad_norm": 1.2310987710952759,
      "learning_rate": 1.0361445783132531e-05,
      "loss": 0.2235,
      "step": 411
    },
    {
      "epoch": 1.4714285714285715,
      "grad_norm": 1.7365578413009644,
      "learning_rate": 1.0337349397590361e-05,
      "loss": 0.2507,
      "step": 412
    },
    {
      "epoch": 1.475,
      "grad_norm": 1.1770654916763306,
      "learning_rate": 1.0313253012048195e-05,
      "loss": 0.2736,
      "step": 413
    },
    {
      "epoch": 1.4785714285714286,
      "grad_norm": 1.2742972373962402,
      "learning_rate": 1.0289156626506025e-05,
      "loss": 0.2828,
      "step": 414
    },
    {
      "epoch": 1.4821428571428572,
      "grad_norm": 1.5117279291152954,
      "learning_rate": 1.0265060240963855e-05,
      "loss": 0.2976,
      "step": 415
    },
    {
      "epoch": 1.4857142857142858,
      "grad_norm": 1.9175688028335571,
      "learning_rate": 1.0240963855421688e-05,
      "loss": 0.2705,
      "step": 416
    },
    {
      "epoch": 1.4892857142857143,
      "grad_norm": 1.6295758485794067,
      "learning_rate": 1.0216867469879518e-05,
      "loss": 0.2502,
      "step": 417
    },
    {
      "epoch": 1.4928571428571429,
      "grad_norm": 1.5502753257751465,
      "learning_rate": 1.019277108433735e-05,
      "loss": 0.2598,
      "step": 418
    },
    {
      "epoch": 1.4964285714285714,
      "grad_norm": 1.3762084245681763,
      "learning_rate": 1.0168674698795182e-05,
      "loss": 0.2016,
      "step": 419
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.3461534976959229,
      "learning_rate": 1.0144578313253014e-05,
      "loss": 0.271,
      "step": 420
    },
    {
      "epoch": 1.5035714285714286,
      "grad_norm": 2.1583733558654785,
      "learning_rate": 1.0120481927710844e-05,
      "loss": 0.2577,
      "step": 421
    },
    {
      "epoch": 1.5071428571428571,
      "grad_norm": 2.103005886077881,
      "learning_rate": 1.0096385542168675e-05,
      "loss": 0.2542,
      "step": 422
    },
    {
      "epoch": 1.5107142857142857,
      "grad_norm": 1.7240009307861328,
      "learning_rate": 1.0072289156626507e-05,
      "loss": 0.2337,
      "step": 423
    },
    {
      "epoch": 1.5142857142857142,
      "grad_norm": 1.2200276851654053,
      "learning_rate": 1.0048192771084337e-05,
      "loss": 0.2351,
      "step": 424
    },
    {
      "epoch": 1.5178571428571428,
      "grad_norm": 1.7021576166152954,
      "learning_rate": 1.002409638554217e-05,
      "loss": 0.2126,
      "step": 425
    },
    {
      "epoch": 1.5214285714285714,
      "grad_norm": 1.2139045000076294,
      "learning_rate": 1e-05,
      "loss": 0.2486,
      "step": 426
    },
    {
      "epoch": 1.525,
      "grad_norm": 2.0788536071777344,
      "learning_rate": 9.975903614457833e-06,
      "loss": 0.2769,
      "step": 427
    },
    {
      "epoch": 1.5285714285714285,
      "grad_norm": 1.6069673299789429,
      "learning_rate": 9.951807228915663e-06,
      "loss": 0.2416,
      "step": 428
    },
    {
      "epoch": 1.532142857142857,
      "grad_norm": 1.8527586460113525,
      "learning_rate": 9.927710843373494e-06,
      "loss": 0.2343,
      "step": 429
    },
    {
      "epoch": 1.5357142857142856,
      "grad_norm": 1.3450332880020142,
      "learning_rate": 9.903614457831326e-06,
      "loss": 0.2465,
      "step": 430
    },
    {
      "epoch": 1.5392857142857141,
      "grad_norm": 1.8055301904678345,
      "learning_rate": 9.879518072289156e-06,
      "loss": 0.238,
      "step": 431
    },
    {
      "epoch": 1.5428571428571427,
      "grad_norm": 1.7985810041427612,
      "learning_rate": 9.855421686746988e-06,
      "loss": 0.2563,
      "step": 432
    },
    {
      "epoch": 1.5464285714285713,
      "grad_norm": 1.7041490077972412,
      "learning_rate": 9.83132530120482e-06,
      "loss": 0.2324,
      "step": 433
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.8655036687850952,
      "learning_rate": 9.807228915662652e-06,
      "loss": 0.2477,
      "step": 434
    },
    {
      "epoch": 1.5535714285714286,
      "grad_norm": 1.4380096197128296,
      "learning_rate": 9.783132530120483e-06,
      "loss": 0.2237,
      "step": 435
    },
    {
      "epoch": 1.5571428571428572,
      "grad_norm": 1.494642972946167,
      "learning_rate": 9.759036144578315e-06,
      "loss": 0.2607,
      "step": 436
    },
    {
      "epoch": 1.5607142857142857,
      "grad_norm": 1.872390866279602,
      "learning_rate": 9.734939759036145e-06,
      "loss": 0.2673,
      "step": 437
    },
    {
      "epoch": 1.5642857142857143,
      "grad_norm": 2.1962599754333496,
      "learning_rate": 9.710843373493977e-06,
      "loss": 0.2502,
      "step": 438
    },
    {
      "epoch": 1.5678571428571428,
      "grad_norm": 1.9034497737884521,
      "learning_rate": 9.686746987951809e-06,
      "loss": 0.2179,
      "step": 439
    },
    {
      "epoch": 1.5714285714285714,
      "grad_norm": 2.9544477462768555,
      "learning_rate": 9.662650602409639e-06,
      "loss": 0.2462,
      "step": 440
    },
    {
      "epoch": 1.575,
      "grad_norm": 1.6722004413604736,
      "learning_rate": 9.63855421686747e-06,
      "loss": 0.2315,
      "step": 441
    },
    {
      "epoch": 1.5785714285714287,
      "grad_norm": 1.765923023223877,
      "learning_rate": 9.614457831325302e-06,
      "loss": 0.2274,
      "step": 442
    },
    {
      "epoch": 1.5821428571428573,
      "grad_norm": 2.1857364177703857,
      "learning_rate": 9.590361445783132e-06,
      "loss": 0.2236,
      "step": 443
    },
    {
      "epoch": 1.5857142857142859,
      "grad_norm": 2.585075616836548,
      "learning_rate": 9.566265060240964e-06,
      "loss": 0.2872,
      "step": 444
    },
    {
      "epoch": 1.5892857142857144,
      "grad_norm": 2.4941563606262207,
      "learning_rate": 9.542168674698796e-06,
      "loss": 0.2723,
      "step": 445
    },
    {
      "epoch": 1.592857142857143,
      "grad_norm": 2.2290515899658203,
      "learning_rate": 9.518072289156628e-06,
      "loss": 0.2276,
      "step": 446
    },
    {
      "epoch": 1.5964285714285715,
      "grad_norm": 2.2033021450042725,
      "learning_rate": 9.49397590361446e-06,
      "loss": 0.2336,
      "step": 447
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.7655328512191772,
      "learning_rate": 9.46987951807229e-06,
      "loss": 0.2761,
      "step": 448
    },
    {
      "epoch": 1.6035714285714286,
      "grad_norm": 1.718553900718689,
      "learning_rate": 9.445783132530121e-06,
      "loss": 0.3003,
      "step": 449
    },
    {
      "epoch": 1.6071428571428572,
      "grad_norm": 1.5696351528167725,
      "learning_rate": 9.421686746987953e-06,
      "loss": 0.2901,
      "step": 450
    },
    {
      "epoch": 1.6107142857142858,
      "grad_norm": 2.248488426208496,
      "learning_rate": 9.397590361445785e-06,
      "loss": 0.2812,
      "step": 451
    },
    {
      "epoch": 1.6142857142857143,
      "grad_norm": 2.4295432567596436,
      "learning_rate": 9.373493975903615e-06,
      "loss": 0.2819,
      "step": 452
    },
    {
      "epoch": 1.6178571428571429,
      "grad_norm": 2.004615545272827,
      "learning_rate": 9.349397590361446e-06,
      "loss": 0.2628,
      "step": 453
    },
    {
      "epoch": 1.6214285714285714,
      "grad_norm": 1.5476031303405762,
      "learning_rate": 9.325301204819278e-06,
      "loss": 0.2175,
      "step": 454
    },
    {
      "epoch": 1.625,
      "grad_norm": 1.8563035726547241,
      "learning_rate": 9.301204819277108e-06,
      "loss": 0.2506,
      "step": 455
    },
    {
      "epoch": 1.6285714285714286,
      "grad_norm": 1.6684377193450928,
      "learning_rate": 9.27710843373494e-06,
      "loss": 0.2638,
      "step": 456
    },
    {
      "epoch": 1.6321428571428571,
      "grad_norm": 1.8064498901367188,
      "learning_rate": 9.253012048192772e-06,
      "loss": 0.2235,
      "step": 457
    },
    {
      "epoch": 1.6357142857142857,
      "grad_norm": 2.108555555343628,
      "learning_rate": 9.228915662650602e-06,
      "loss": 0.2872,
      "step": 458
    },
    {
      "epoch": 1.6392857142857142,
      "grad_norm": 1.745644450187683,
      "learning_rate": 9.204819277108434e-06,
      "loss": 0.237,
      "step": 459
    },
    {
      "epoch": 1.6428571428571428,
      "grad_norm": 2.444349765777588,
      "learning_rate": 9.180722891566265e-06,
      "loss": 0.2697,
      "step": 460
    },
    {
      "epoch": 1.6464285714285714,
      "grad_norm": 1.4413493871688843,
      "learning_rate": 9.156626506024097e-06,
      "loss": 0.2442,
      "step": 461
    },
    {
      "epoch": 1.65,
      "grad_norm": 2.1372671127319336,
      "learning_rate": 9.132530120481929e-06,
      "loss": 0.2702,
      "step": 462
    },
    {
      "epoch": 1.6535714285714285,
      "grad_norm": 3.4807326793670654,
      "learning_rate": 9.10843373493976e-06,
      "loss": 0.2662,
      "step": 463
    },
    {
      "epoch": 1.657142857142857,
      "grad_norm": 1.6902329921722412,
      "learning_rate": 9.08433734939759e-06,
      "loss": 0.2344,
      "step": 464
    },
    {
      "epoch": 1.6607142857142856,
      "grad_norm": 2.405263662338257,
      "learning_rate": 9.060240963855423e-06,
      "loss": 0.205,
      "step": 465
    },
    {
      "epoch": 1.6642857142857141,
      "grad_norm": 1.5615915060043335,
      "learning_rate": 9.036144578313254e-06,
      "loss": 0.2344,
      "step": 466
    },
    {
      "epoch": 1.6678571428571427,
      "grad_norm": 1.592972993850708,
      "learning_rate": 9.012048192771084e-06,
      "loss": 0.2095,
      "step": 467
    },
    {
      "epoch": 1.6714285714285713,
      "grad_norm": 2.08638858795166,
      "learning_rate": 8.987951807228916e-06,
      "loss": 0.2388,
      "step": 468
    },
    {
      "epoch": 1.675,
      "grad_norm": 3.090769052505493,
      "learning_rate": 8.963855421686748e-06,
      "loss": 0.3142,
      "step": 469
    },
    {
      "epoch": 1.6785714285714286,
      "grad_norm": 2.1130919456481934,
      "learning_rate": 8.939759036144578e-06,
      "loss": 0.1967,
      "step": 470
    },
    {
      "epoch": 1.6821428571428572,
      "grad_norm": 2.3148999214172363,
      "learning_rate": 8.91566265060241e-06,
      "loss": 0.2413,
      "step": 471
    },
    {
      "epoch": 1.6857142857142857,
      "grad_norm": 2.234128952026367,
      "learning_rate": 8.891566265060241e-06,
      "loss": 0.2551,
      "step": 472
    },
    {
      "epoch": 1.6892857142857143,
      "grad_norm": 2.3875458240509033,
      "learning_rate": 8.867469879518073e-06,
      "loss": 0.2908,
      "step": 473
    },
    {
      "epoch": 1.6928571428571428,
      "grad_norm": 2.227091073989868,
      "learning_rate": 8.843373493975905e-06,
      "loss": 0.2646,
      "step": 474
    },
    {
      "epoch": 1.6964285714285714,
      "grad_norm": 2.568981409072876,
      "learning_rate": 8.819277108433735e-06,
      "loss": 0.2141,
      "step": 475
    },
    {
      "epoch": 1.7,
      "grad_norm": 2.122021198272705,
      "learning_rate": 8.795180722891567e-06,
      "loss": 0.2422,
      "step": 476
    },
    {
      "epoch": 1.7035714285714287,
      "grad_norm": 3.2517807483673096,
      "learning_rate": 8.771084337349399e-06,
      "loss": 0.2042,
      "step": 477
    },
    {
      "epoch": 1.7071428571428573,
      "grad_norm": 2.3036274909973145,
      "learning_rate": 8.74698795180723e-06,
      "loss": 0.2448,
      "step": 478
    },
    {
      "epoch": 1.7107142857142859,
      "grad_norm": 1.9101428985595703,
      "learning_rate": 8.722891566265062e-06,
      "loss": 0.2592,
      "step": 479
    },
    {
      "epoch": 1.7142857142857144,
      "grad_norm": 2.197185754776001,
      "learning_rate": 8.698795180722892e-06,
      "loss": 0.2382,
      "step": 480
    },
    {
      "epoch": 1.717857142857143,
      "grad_norm": 2.7209224700927734,
      "learning_rate": 8.674698795180724e-06,
      "loss": 0.2181,
      "step": 481
    },
    {
      "epoch": 1.7214285714285715,
      "grad_norm": 2.243255615234375,
      "learning_rate": 8.650602409638556e-06,
      "loss": 0.2305,
      "step": 482
    },
    {
      "epoch": 1.725,
      "grad_norm": 1.4459376335144043,
      "learning_rate": 8.626506024096386e-06,
      "loss": 0.2034,
      "step": 483
    },
    {
      "epoch": 1.7285714285714286,
      "grad_norm": 1.9521514177322388,
      "learning_rate": 8.602409638554217e-06,
      "loss": 0.2502,
      "step": 484
    },
    {
      "epoch": 1.7321428571428572,
      "grad_norm": 2.2483267784118652,
      "learning_rate": 8.57831325301205e-06,
      "loss": 0.2539,
      "step": 485
    },
    {
      "epoch": 1.7357142857142858,
      "grad_norm": 1.6432291269302368,
      "learning_rate": 8.55421686746988e-06,
      "loss": 0.2171,
      "step": 486
    },
    {
      "epoch": 1.7392857142857143,
      "grad_norm": 1.2445197105407715,
      "learning_rate": 8.530120481927711e-06,
      "loss": 0.2225,
      "step": 487
    },
    {
      "epoch": 1.7428571428571429,
      "grad_norm": 1.8450125455856323,
      "learning_rate": 8.506024096385543e-06,
      "loss": 0.2254,
      "step": 488
    },
    {
      "epoch": 1.7464285714285714,
      "grad_norm": 2.056706666946411,
      "learning_rate": 8.481927710843375e-06,
      "loss": 0.2003,
      "step": 489
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.5497369766235352,
      "learning_rate": 8.457831325301206e-06,
      "loss": 0.2594,
      "step": 490
    },
    {
      "epoch": 1.7535714285714286,
      "grad_norm": 1.9633805751800537,
      "learning_rate": 8.433734939759038e-06,
      "loss": 0.2419,
      "step": 491
    },
    {
      "epoch": 1.7571428571428571,
      "grad_norm": 2.1597740650177,
      "learning_rate": 8.409638554216868e-06,
      "loss": 0.226,
      "step": 492
    },
    {
      "epoch": 1.7607142857142857,
      "grad_norm": 1.9866681098937988,
      "learning_rate": 8.3855421686747e-06,
      "loss": 0.2298,
      "step": 493
    },
    {
      "epoch": 1.7642857142857142,
      "grad_norm": 1.5460470914840698,
      "learning_rate": 8.361445783132532e-06,
      "loss": 0.2359,
      "step": 494
    },
    {
      "epoch": 1.7678571428571428,
      "grad_norm": 2.5391106605529785,
      "learning_rate": 8.337349397590362e-06,
      "loss": 0.2624,
      "step": 495
    },
    {
      "epoch": 1.7714285714285714,
      "grad_norm": 2.5375759601593018,
      "learning_rate": 8.313253012048194e-06,
      "loss": 0.2873,
      "step": 496
    },
    {
      "epoch": 1.775,
      "grad_norm": 1.9621385335922241,
      "learning_rate": 8.289156626506025e-06,
      "loss": 0.2107,
      "step": 497
    },
    {
      "epoch": 1.7785714285714285,
      "grad_norm": 2.1324961185455322,
      "learning_rate": 8.265060240963855e-06,
      "loss": 0.2388,
      "step": 498
    },
    {
      "epoch": 1.782142857142857,
      "grad_norm": 1.783666729927063,
      "learning_rate": 8.240963855421687e-06,
      "loss": 0.2424,
      "step": 499
    },
    {
      "epoch": 1.7857142857142856,
      "grad_norm": 1.5546287298202515,
      "learning_rate": 8.216867469879519e-06,
      "loss": 0.2667,
      "step": 500
    },
    {
      "epoch": 1.7892857142857141,
      "grad_norm": 1.7783713340759277,
      "learning_rate": 8.19277108433735e-06,
      "loss": 0.2366,
      "step": 501
    },
    {
      "epoch": 1.7928571428571427,
      "grad_norm": 1.863120675086975,
      "learning_rate": 8.16867469879518e-06,
      "loss": 0.245,
      "step": 502
    },
    {
      "epoch": 1.7964285714285713,
      "grad_norm": 2.039910316467285,
      "learning_rate": 8.144578313253012e-06,
      "loss": 0.252,
      "step": 503
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.6867327690124512,
      "learning_rate": 8.120481927710844e-06,
      "loss": 0.2619,
      "step": 504
    },
    {
      "epoch": 1.8035714285714286,
      "grad_norm": 1.8627351522445679,
      "learning_rate": 8.096385542168676e-06,
      "loss": 0.2707,
      "step": 505
    },
    {
      "epoch": 1.8071428571428572,
      "grad_norm": 2.401160478591919,
      "learning_rate": 8.072289156626508e-06,
      "loss": 0.2854,
      "step": 506
    },
    {
      "epoch": 1.8107142857142857,
      "grad_norm": 2.0462899208068848,
      "learning_rate": 8.048192771084338e-06,
      "loss": 0.2453,
      "step": 507
    },
    {
      "epoch": 1.8142857142857143,
      "grad_norm": 1.894832968711853,
      "learning_rate": 8.02409638554217e-06,
      "loss": 0.2488,
      "step": 508
    },
    {
      "epoch": 1.8178571428571428,
      "grad_norm": 1.6588412523269653,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.1909,
      "step": 509
    },
    {
      "epoch": 1.8214285714285714,
      "grad_norm": 2.502092123031616,
      "learning_rate": 7.975903614457831e-06,
      "loss": 0.2384,
      "step": 510
    },
    {
      "epoch": 1.825,
      "grad_norm": 2.274315357208252,
      "learning_rate": 7.951807228915663e-06,
      "loss": 0.2431,
      "step": 511
    },
    {
      "epoch": 1.8285714285714287,
      "grad_norm": 1.5894771814346313,
      "learning_rate": 7.927710843373495e-06,
      "loss": 0.2444,
      "step": 512
    },
    {
      "epoch": 1.8321428571428573,
      "grad_norm": 1.7286573648452759,
      "learning_rate": 7.903614457831325e-06,
      "loss": 0.2027,
      "step": 513
    },
    {
      "epoch": 1.8357142857142859,
      "grad_norm": 2.8332021236419678,
      "learning_rate": 7.879518072289157e-06,
      "loss": 0.1963,
      "step": 514
    },
    {
      "epoch": 1.8392857142857144,
      "grad_norm": 2.6192591190338135,
      "learning_rate": 7.855421686746989e-06,
      "loss": 0.2469,
      "step": 515
    },
    {
      "epoch": 1.842857142857143,
      "grad_norm": 1.7648661136627197,
      "learning_rate": 7.83132530120482e-06,
      "loss": 0.2221,
      "step": 516
    },
    {
      "epoch": 1.8464285714285715,
      "grad_norm": 1.7153757810592651,
      "learning_rate": 7.807228915662652e-06,
      "loss": 0.2489,
      "step": 517
    },
    {
      "epoch": 1.85,
      "grad_norm": 1.9489500522613525,
      "learning_rate": 7.783132530120484e-06,
      "loss": 0.2292,
      "step": 518
    },
    {
      "epoch": 1.8535714285714286,
      "grad_norm": 2.7778990268707275,
      "learning_rate": 7.759036144578314e-06,
      "loss": 0.2538,
      "step": 519
    },
    {
      "epoch": 1.8571428571428572,
      "grad_norm": 1.5496187210083008,
      "learning_rate": 7.734939759036146e-06,
      "loss": 0.2457,
      "step": 520
    },
    {
      "epoch": 1.8607142857142858,
      "grad_norm": 2.250802516937256,
      "learning_rate": 7.710843373493977e-06,
      "loss": 0.1872,
      "step": 521
    },
    {
      "epoch": 1.8642857142857143,
      "grad_norm": 2.484518051147461,
      "learning_rate": 7.686746987951807e-06,
      "loss": 0.2441,
      "step": 522
    },
    {
      "epoch": 1.8678571428571429,
      "grad_norm": 2.542759418487549,
      "learning_rate": 7.66265060240964e-06,
      "loss": 0.2424,
      "step": 523
    },
    {
      "epoch": 1.8714285714285714,
      "grad_norm": 1.5123354196548462,
      "learning_rate": 7.638554216867471e-06,
      "loss": 0.2829,
      "step": 524
    },
    {
      "epoch": 1.875,
      "grad_norm": 2.3081579208374023,
      "learning_rate": 7.614457831325302e-06,
      "loss": 0.2149,
      "step": 525
    },
    {
      "epoch": 1.8785714285714286,
      "grad_norm": 1.7521510124206543,
      "learning_rate": 7.590361445783133e-06,
      "loss": 0.2544,
      "step": 526
    },
    {
      "epoch": 1.8821428571428571,
      "grad_norm": 1.5761929750442505,
      "learning_rate": 7.5662650602409645e-06,
      "loss": 0.2154,
      "step": 527
    },
    {
      "epoch": 1.8857142857142857,
      "grad_norm": 2.6116113662719727,
      "learning_rate": 7.5421686746987955e-06,
      "loss": 0.2156,
      "step": 528
    },
    {
      "epoch": 1.8892857142857142,
      "grad_norm": 1.8486281633377075,
      "learning_rate": 7.518072289156627e-06,
      "loss": 0.2075,
      "step": 529
    },
    {
      "epoch": 1.8928571428571428,
      "grad_norm": 2.315544366836548,
      "learning_rate": 7.493975903614459e-06,
      "loss": 0.2467,
      "step": 530
    },
    {
      "epoch": 1.8964285714285714,
      "grad_norm": 3.047973871231079,
      "learning_rate": 7.469879518072289e-06,
      "loss": 0.2352,
      "step": 531
    },
    {
      "epoch": 1.9,
      "grad_norm": 4.383033275604248,
      "learning_rate": 7.445783132530121e-06,
      "loss": 0.2468,
      "step": 532
    },
    {
      "epoch": 1.9035714285714285,
      "grad_norm": 1.8312044143676758,
      "learning_rate": 7.4216867469879526e-06,
      "loss": 0.2012,
      "step": 533
    },
    {
      "epoch": 1.907142857142857,
      "grad_norm": 2.065462589263916,
      "learning_rate": 7.3975903614457835e-06,
      "loss": 0.2225,
      "step": 534
    },
    {
      "epoch": 1.9107142857142856,
      "grad_norm": 3.071892499923706,
      "learning_rate": 7.373493975903615e-06,
      "loss": 0.2216,
      "step": 535
    },
    {
      "epoch": 1.9142857142857141,
      "grad_norm": 2.3891406059265137,
      "learning_rate": 7.349397590361447e-06,
      "loss": 0.2194,
      "step": 536
    },
    {
      "epoch": 1.9178571428571427,
      "grad_norm": 1.8992329835891724,
      "learning_rate": 7.325301204819277e-06,
      "loss": 0.2353,
      "step": 537
    },
    {
      "epoch": 1.9214285714285713,
      "grad_norm": 1.6681828498840332,
      "learning_rate": 7.301204819277109e-06,
      "loss": 0.2063,
      "step": 538
    },
    {
      "epoch": 1.925,
      "grad_norm": 1.7732757329940796,
      "learning_rate": 7.277108433734941e-06,
      "loss": 0.2234,
      "step": 539
    },
    {
      "epoch": 1.9285714285714286,
      "grad_norm": 2.0851078033447266,
      "learning_rate": 7.2530120481927715e-06,
      "loss": 0.2378,
      "step": 540
    },
    {
      "epoch": 1.9321428571428572,
      "grad_norm": 1.7035201787948608,
      "learning_rate": 7.228915662650603e-06,
      "loss": 0.2161,
      "step": 541
    },
    {
      "epoch": 1.9357142857142857,
      "grad_norm": 2.0794599056243896,
      "learning_rate": 7.204819277108435e-06,
      "loss": 0.2163,
      "step": 542
    },
    {
      "epoch": 1.9392857142857143,
      "grad_norm": 3.0095877647399902,
      "learning_rate": 7.180722891566265e-06,
      "loss": 0.2714,
      "step": 543
    },
    {
      "epoch": 1.9428571428571428,
      "grad_norm": 2.0260086059570312,
      "learning_rate": 7.156626506024097e-06,
      "loss": 0.2058,
      "step": 544
    },
    {
      "epoch": 1.9464285714285714,
      "grad_norm": 2.599011182785034,
      "learning_rate": 7.132530120481929e-06,
      "loss": 0.2117,
      "step": 545
    },
    {
      "epoch": 1.95,
      "grad_norm": 2.9655420780181885,
      "learning_rate": 7.1084337349397595e-06,
      "loss": 0.2562,
      "step": 546
    },
    {
      "epoch": 1.9535714285714287,
      "grad_norm": 2.377243757247925,
      "learning_rate": 7.084337349397591e-06,
      "loss": 0.189,
      "step": 547
    },
    {
      "epoch": 1.9571428571428573,
      "grad_norm": 1.7378019094467163,
      "learning_rate": 7.060240963855422e-06,
      "loss": 0.2289,
      "step": 548
    },
    {
      "epoch": 1.9607142857142859,
      "grad_norm": 2.3105125427246094,
      "learning_rate": 7.036144578313253e-06,
      "loss": 0.2698,
      "step": 549
    },
    {
      "epoch": 1.9642857142857144,
      "grad_norm": 1.9355289936065674,
      "learning_rate": 7.012048192771085e-06,
      "loss": 0.26,
      "step": 550
    },
    {
      "epoch": 1.967857142857143,
      "grad_norm": 2.447807550430298,
      "learning_rate": 6.987951807228917e-06,
      "loss": 0.2253,
      "step": 551
    },
    {
      "epoch": 1.9714285714285715,
      "grad_norm": 1.8375507593154907,
      "learning_rate": 6.963855421686747e-06,
      "loss": 0.2054,
      "step": 552
    },
    {
      "epoch": 1.975,
      "grad_norm": 2.2278947830200195,
      "learning_rate": 6.9397590361445784e-06,
      "loss": 0.2192,
      "step": 553
    },
    {
      "epoch": 1.9785714285714286,
      "grad_norm": 1.6392621994018555,
      "learning_rate": 6.91566265060241e-06,
      "loss": 0.2093,
      "step": 554
    },
    {
      "epoch": 1.9821428571428572,
      "grad_norm": 2.0934202671051025,
      "learning_rate": 6.891566265060241e-06,
      "loss": 0.2193,
      "step": 555
    },
    {
      "epoch": 1.9857142857142858,
      "grad_norm": 2.2979156970977783,
      "learning_rate": 6.867469879518073e-06,
      "loss": 0.2311,
      "step": 556
    },
    {
      "epoch": 1.9892857142857143,
      "grad_norm": 1.883895993232727,
      "learning_rate": 6.843373493975905e-06,
      "loss": 0.1829,
      "step": 557
    },
    {
      "epoch": 1.9928571428571429,
      "grad_norm": 1.6398755311965942,
      "learning_rate": 6.819277108433735e-06,
      "loss": 0.2125,
      "step": 558
    },
    {
      "epoch": 1.9964285714285714,
      "grad_norm": 1.9010266065597534,
      "learning_rate": 6.7951807228915665e-06,
      "loss": 0.2027,
      "step": 559
    },
    {
      "epoch": 2.0,
      "grad_norm": 2.9967663288116455,
      "learning_rate": 6.771084337349398e-06,
      "loss": 0.2224,
      "step": 560
    },
    {
      "epoch": 2.0035714285714286,
      "grad_norm": 1.9924917221069336,
      "learning_rate": 6.746987951807229e-06,
      "loss": 0.2577,
      "step": 561
    },
    {
      "epoch": 2.007142857142857,
      "grad_norm": 2.456669569015503,
      "learning_rate": 6.722891566265061e-06,
      "loss": 0.2215,
      "step": 562
    },
    {
      "epoch": 2.0107142857142857,
      "grad_norm": 1.3211408853530884,
      "learning_rate": 6.698795180722893e-06,
      "loss": 0.1945,
      "step": 563
    },
    {
      "epoch": 2.0142857142857142,
      "grad_norm": 1.5696161985397339,
      "learning_rate": 6.674698795180723e-06,
      "loss": 0.2452,
      "step": 564
    },
    {
      "epoch": 2.017857142857143,
      "grad_norm": 2.5438005924224854,
      "learning_rate": 6.6506024096385545e-06,
      "loss": 0.2081,
      "step": 565
    },
    {
      "epoch": 2.0214285714285714,
      "grad_norm": 1.5731098651885986,
      "learning_rate": 6.626506024096386e-06,
      "loss": 0.2649,
      "step": 566
    },
    {
      "epoch": 2.025,
      "grad_norm": 1.9423143863677979,
      "learning_rate": 6.602409638554217e-06,
      "loss": 0.2841,
      "step": 567
    },
    {
      "epoch": 2.0285714285714285,
      "grad_norm": 3.1552340984344482,
      "learning_rate": 6.578313253012049e-06,
      "loss": 0.226,
      "step": 568
    },
    {
      "epoch": 2.032142857142857,
      "grad_norm": 2.1534693241119385,
      "learning_rate": 6.554216867469881e-06,
      "loss": 0.2134,
      "step": 569
    },
    {
      "epoch": 2.0357142857142856,
      "grad_norm": 1.876477837562561,
      "learning_rate": 6.530120481927711e-06,
      "loss": 0.2201,
      "step": 570
    },
    {
      "epoch": 2.039285714285714,
      "grad_norm": 2.869372844696045,
      "learning_rate": 6.5060240963855425e-06,
      "loss": 0.2316,
      "step": 571
    },
    {
      "epoch": 2.0428571428571427,
      "grad_norm": 1.8867770433425903,
      "learning_rate": 6.481927710843374e-06,
      "loss": 0.207,
      "step": 572
    },
    {
      "epoch": 2.0464285714285713,
      "grad_norm": 1.5530405044555664,
      "learning_rate": 6.457831325301205e-06,
      "loss": 0.2142,
      "step": 573
    },
    {
      "epoch": 2.05,
      "grad_norm": 2.764350652694702,
      "learning_rate": 6.433734939759036e-06,
      "loss": 0.2271,
      "step": 574
    },
    {
      "epoch": 2.0535714285714284,
      "grad_norm": 1.798702597618103,
      "learning_rate": 6.409638554216868e-06,
      "loss": 0.2202,
      "step": 575
    },
    {
      "epoch": 2.057142857142857,
      "grad_norm": 1.603438377380371,
      "learning_rate": 6.385542168674699e-06,
      "loss": 0.1933,
      "step": 576
    },
    {
      "epoch": 2.0607142857142855,
      "grad_norm": 1.6646263599395752,
      "learning_rate": 6.3614457831325305e-06,
      "loss": 0.22,
      "step": 577
    },
    {
      "epoch": 2.064285714285714,
      "grad_norm": 1.879719853401184,
      "learning_rate": 6.337349397590362e-06,
      "loss": 0.209,
      "step": 578
    },
    {
      "epoch": 2.067857142857143,
      "grad_norm": 2.131967067718506,
      "learning_rate": 6.313253012048192e-06,
      "loss": 0.2172,
      "step": 579
    },
    {
      "epoch": 2.0714285714285716,
      "grad_norm": 1.8393142223358154,
      "learning_rate": 6.289156626506024e-06,
      "loss": 0.1873,
      "step": 580
    },
    {
      "epoch": 2.075,
      "grad_norm": 2.1107208728790283,
      "learning_rate": 6.265060240963856e-06,
      "loss": 0.2056,
      "step": 581
    },
    {
      "epoch": 2.0785714285714287,
      "grad_norm": 2.112088441848755,
      "learning_rate": 6.240963855421688e-06,
      "loss": 0.2023,
      "step": 582
    },
    {
      "epoch": 2.0821428571428573,
      "grad_norm": 1.6353298425674438,
      "learning_rate": 6.2168674698795185e-06,
      "loss": 0.2027,
      "step": 583
    },
    {
      "epoch": 2.085714285714286,
      "grad_norm": 2.1306633949279785,
      "learning_rate": 6.19277108433735e-06,
      "loss": 0.2047,
      "step": 584
    },
    {
      "epoch": 2.0892857142857144,
      "grad_norm": 2.139453887939453,
      "learning_rate": 6.168674698795182e-06,
      "loss": 0.2107,
      "step": 585
    },
    {
      "epoch": 2.092857142857143,
      "grad_norm": 1.9474953413009644,
      "learning_rate": 6.144578313253012e-06,
      "loss": 0.2164,
      "step": 586
    },
    {
      "epoch": 2.0964285714285715,
      "grad_norm": 1.9328442811965942,
      "learning_rate": 6.120481927710844e-06,
      "loss": 0.203,
      "step": 587
    },
    {
      "epoch": 2.1,
      "grad_norm": 2.643498420715332,
      "learning_rate": 6.096385542168676e-06,
      "loss": 0.2043,
      "step": 588
    },
    {
      "epoch": 2.1035714285714286,
      "grad_norm": 1.8860048055648804,
      "learning_rate": 6.0722891566265066e-06,
      "loss": 0.2104,
      "step": 589
    },
    {
      "epoch": 2.107142857142857,
      "grad_norm": 2.601428508758545,
      "learning_rate": 6.048192771084338e-06,
      "loss": 0.1912,
      "step": 590
    },
    {
      "epoch": 2.1107142857142858,
      "grad_norm": 2.618161916732788,
      "learning_rate": 6.02409638554217e-06,
      "loss": 0.2067,
      "step": 591
    },
    {
      "epoch": 2.1142857142857143,
      "grad_norm": 2.126477003097534,
      "learning_rate": 6e-06,
      "loss": 0.199,
      "step": 592
    },
    {
      "epoch": 2.117857142857143,
      "grad_norm": 2.1125950813293457,
      "learning_rate": 5.975903614457832e-06,
      "loss": 0.2339,
      "step": 593
    },
    {
      "epoch": 2.1214285714285714,
      "grad_norm": 2.487715482711792,
      "learning_rate": 5.951807228915664e-06,
      "loss": 0.2085,
      "step": 594
    },
    {
      "epoch": 2.125,
      "grad_norm": 1.800325632095337,
      "learning_rate": 5.927710843373495e-06,
      "loss": 0.2135,
      "step": 595
    },
    {
      "epoch": 2.1285714285714286,
      "grad_norm": 2.1080658435821533,
      "learning_rate": 5.9036144578313255e-06,
      "loss": 0.1971,
      "step": 596
    },
    {
      "epoch": 2.132142857142857,
      "grad_norm": 1.9571291208267212,
      "learning_rate": 5.879518072289157e-06,
      "loss": 0.2135,
      "step": 597
    },
    {
      "epoch": 2.1357142857142857,
      "grad_norm": 2.1762397289276123,
      "learning_rate": 5.855421686746988e-06,
      "loss": 0.2052,
      "step": 598
    },
    {
      "epoch": 2.1392857142857142,
      "grad_norm": 1.9109700918197632,
      "learning_rate": 5.83132530120482e-06,
      "loss": 0.2301,
      "step": 599
    },
    {
      "epoch": 2.142857142857143,
      "grad_norm": 2.5719525814056396,
      "learning_rate": 5.807228915662652e-06,
      "loss": 0.2252,
      "step": 600
    },
    {
      "epoch": 2.1464285714285714,
      "grad_norm": 2.9976744651794434,
      "learning_rate": 5.783132530120482e-06,
      "loss": 0.1585,
      "step": 601
    },
    {
      "epoch": 2.15,
      "grad_norm": 2.0307509899139404,
      "learning_rate": 5.7590361445783135e-06,
      "loss": 0.2312,
      "step": 602
    },
    {
      "epoch": 2.1535714285714285,
      "grad_norm": 2.085061550140381,
      "learning_rate": 5.734939759036145e-06,
      "loss": 0.2756,
      "step": 603
    },
    {
      "epoch": 2.157142857142857,
      "grad_norm": 2.0155274868011475,
      "learning_rate": 5.710843373493976e-06,
      "loss": 0.2043,
      "step": 604
    },
    {
      "epoch": 2.1607142857142856,
      "grad_norm": 2.642495632171631,
      "learning_rate": 5.686746987951808e-06,
      "loss": 0.2473,
      "step": 605
    },
    {
      "epoch": 2.164285714285714,
      "grad_norm": 1.73564875125885,
      "learning_rate": 5.66265060240964e-06,
      "loss": 0.2159,
      "step": 606
    },
    {
      "epoch": 2.1678571428571427,
      "grad_norm": 3.334839344024658,
      "learning_rate": 5.63855421686747e-06,
      "loss": 0.2097,
      "step": 607
    },
    {
      "epoch": 2.1714285714285713,
      "grad_norm": 2.5684285163879395,
      "learning_rate": 5.6144578313253015e-06,
      "loss": 0.2263,
      "step": 608
    },
    {
      "epoch": 2.175,
      "grad_norm": 1.9400930404663086,
      "learning_rate": 5.590361445783133e-06,
      "loss": 0.1931,
      "step": 609
    },
    {
      "epoch": 2.1785714285714284,
      "grad_norm": 2.4182348251342773,
      "learning_rate": 5.566265060240964e-06,
      "loss": 0.2278,
      "step": 610
    },
    {
      "epoch": 2.182142857142857,
      "grad_norm": 1.8823835849761963,
      "learning_rate": 5.542168674698796e-06,
      "loss": 0.1942,
      "step": 611
    },
    {
      "epoch": 2.185714285714286,
      "grad_norm": 2.119044065475464,
      "learning_rate": 5.518072289156628e-06,
      "loss": 0.2025,
      "step": 612
    },
    {
      "epoch": 2.189285714285714,
      "grad_norm": 3.4067628383636475,
      "learning_rate": 5.493975903614458e-06,
      "loss": 0.1764,
      "step": 613
    },
    {
      "epoch": 2.192857142857143,
      "grad_norm": 2.1889102458953857,
      "learning_rate": 5.4698795180722896e-06,
      "loss": 0.2218,
      "step": 614
    },
    {
      "epoch": 2.1964285714285716,
      "grad_norm": 2.177528142929077,
      "learning_rate": 5.445783132530121e-06,
      "loss": 0.1753,
      "step": 615
    },
    {
      "epoch": 2.2,
      "grad_norm": 2.036409854888916,
      "learning_rate": 5.421686746987952e-06,
      "loss": 0.1715,
      "step": 616
    },
    {
      "epoch": 2.2035714285714287,
      "grad_norm": 2.1374380588531494,
      "learning_rate": 5.397590361445784e-06,
      "loss": 0.1991,
      "step": 617
    },
    {
      "epoch": 2.2071428571428573,
      "grad_norm": 1.7683205604553223,
      "learning_rate": 5.373493975903615e-06,
      "loss": 0.2112,
      "step": 618
    },
    {
      "epoch": 2.210714285714286,
      "grad_norm": 2.8252906799316406,
      "learning_rate": 5.349397590361446e-06,
      "loss": 0.2283,
      "step": 619
    },
    {
      "epoch": 2.2142857142857144,
      "grad_norm": 1.9310336112976074,
      "learning_rate": 5.325301204819278e-06,
      "loss": 0.2498,
      "step": 620
    },
    {
      "epoch": 2.217857142857143,
      "grad_norm": 1.8122859001159668,
      "learning_rate": 5.301204819277109e-06,
      "loss": 0.1918,
      "step": 621
    },
    {
      "epoch": 2.2214285714285715,
      "grad_norm": 2.390852451324463,
      "learning_rate": 5.27710843373494e-06,
      "loss": 0.2,
      "step": 622
    },
    {
      "epoch": 2.225,
      "grad_norm": 2.288567543029785,
      "learning_rate": 5.253012048192771e-06,
      "loss": 0.2127,
      "step": 623
    },
    {
      "epoch": 2.2285714285714286,
      "grad_norm": 2.7530453205108643,
      "learning_rate": 5.228915662650603e-06,
      "loss": 0.2095,
      "step": 624
    },
    {
      "epoch": 2.232142857142857,
      "grad_norm": 2.3133819103240967,
      "learning_rate": 5.204819277108434e-06,
      "loss": 0.2344,
      "step": 625
    },
    {
      "epoch": 2.2357142857142858,
      "grad_norm": 2.6106109619140625,
      "learning_rate": 5.180722891566266e-06,
      "loss": 0.2389,
      "step": 626
    },
    {
      "epoch": 2.2392857142857143,
      "grad_norm": 2.3948605060577393,
      "learning_rate": 5.156626506024097e-06,
      "loss": 0.2562,
      "step": 627
    },
    {
      "epoch": 2.242857142857143,
      "grad_norm": 1.9331870079040527,
      "learning_rate": 5.132530120481927e-06,
      "loss": 0.1844,
      "step": 628
    },
    {
      "epoch": 2.2464285714285714,
      "grad_norm": 1.8171887397766113,
      "learning_rate": 5.108433734939759e-06,
      "loss": 0.1796,
      "step": 629
    },
    {
      "epoch": 2.25,
      "grad_norm": 2.182605504989624,
      "learning_rate": 5.084337349397591e-06,
      "loss": 0.1956,
      "step": 630
    },
    {
      "epoch": 2.2535714285714286,
      "grad_norm": 3.7280354499816895,
      "learning_rate": 5.060240963855422e-06,
      "loss": 0.2188,
      "step": 631
    },
    {
      "epoch": 2.257142857142857,
      "grad_norm": 2.933079481124878,
      "learning_rate": 5.036144578313254e-06,
      "loss": 0.1924,
      "step": 632
    },
    {
      "epoch": 2.2607142857142857,
      "grad_norm": 2.6106624603271484,
      "learning_rate": 5.012048192771085e-06,
      "loss": 0.1988,
      "step": 633
    },
    {
      "epoch": 2.2642857142857142,
      "grad_norm": 1.841806173324585,
      "learning_rate": 4.987951807228916e-06,
      "loss": 0.2083,
      "step": 634
    },
    {
      "epoch": 2.267857142857143,
      "grad_norm": 1.902457356452942,
      "learning_rate": 4.963855421686747e-06,
      "loss": 0.1871,
      "step": 635
    },
    {
      "epoch": 2.2714285714285714,
      "grad_norm": 1.9410107135772705,
      "learning_rate": 4.939759036144578e-06,
      "loss": 0.1759,
      "step": 636
    },
    {
      "epoch": 2.275,
      "grad_norm": 2.1743314266204834,
      "learning_rate": 4.91566265060241e-06,
      "loss": 0.178,
      "step": 637
    },
    {
      "epoch": 2.2785714285714285,
      "grad_norm": 2.1922147274017334,
      "learning_rate": 4.891566265060242e-06,
      "loss": 0.1819,
      "step": 638
    },
    {
      "epoch": 2.282142857142857,
      "grad_norm": 2.0031142234802246,
      "learning_rate": 4.8674698795180725e-06,
      "loss": 0.2119,
      "step": 639
    },
    {
      "epoch": 2.2857142857142856,
      "grad_norm": 2.798125982284546,
      "learning_rate": 4.843373493975904e-06,
      "loss": 0.2231,
      "step": 640
    },
    {
      "epoch": 2.289285714285714,
      "grad_norm": 2.0223746299743652,
      "learning_rate": 4.819277108433735e-06,
      "loss": 0.228,
      "step": 641
    },
    {
      "epoch": 2.2928571428571427,
      "grad_norm": 1.6766189336776733,
      "learning_rate": 4.795180722891566e-06,
      "loss": 0.2498,
      "step": 642
    },
    {
      "epoch": 2.2964285714285713,
      "grad_norm": 2.705803155899048,
      "learning_rate": 4.771084337349398e-06,
      "loss": 0.2105,
      "step": 643
    },
    {
      "epoch": 2.3,
      "grad_norm": 1.9876593351364136,
      "learning_rate": 4.74698795180723e-06,
      "loss": 0.2042,
      "step": 644
    },
    {
      "epoch": 2.3035714285714284,
      "grad_norm": 2.12551212310791,
      "learning_rate": 4.7228915662650606e-06,
      "loss": 0.1749,
      "step": 645
    },
    {
      "epoch": 2.307142857142857,
      "grad_norm": 2.510690927505493,
      "learning_rate": 4.698795180722892e-06,
      "loss": 0.1971,
      "step": 646
    },
    {
      "epoch": 2.310714285714286,
      "grad_norm": 2.5160317420959473,
      "learning_rate": 4.674698795180723e-06,
      "loss": 0.2226,
      "step": 647
    },
    {
      "epoch": 2.314285714285714,
      "grad_norm": 2.3504436016082764,
      "learning_rate": 4.650602409638554e-06,
      "loss": 0.1947,
      "step": 648
    },
    {
      "epoch": 2.317857142857143,
      "grad_norm": 2.3639028072357178,
      "learning_rate": 4.626506024096386e-06,
      "loss": 0.2201,
      "step": 649
    },
    {
      "epoch": 2.3214285714285716,
      "grad_norm": 3.310441493988037,
      "learning_rate": 4.602409638554217e-06,
      "loss": 0.1816,
      "step": 650
    },
    {
      "epoch": 2.325,
      "grad_norm": 3.4014737606048584,
      "learning_rate": 4.578313253012049e-06,
      "loss": 0.2228,
      "step": 651
    },
    {
      "epoch": 2.3285714285714287,
      "grad_norm": 1.8368643522262573,
      "learning_rate": 4.55421686746988e-06,
      "loss": 0.181,
      "step": 652
    },
    {
      "epoch": 2.3321428571428573,
      "grad_norm": 1.8005931377410889,
      "learning_rate": 4.530120481927711e-06,
      "loss": 0.191,
      "step": 653
    },
    {
      "epoch": 2.335714285714286,
      "grad_norm": 2.050571918487549,
      "learning_rate": 4.506024096385542e-06,
      "loss": 0.2145,
      "step": 654
    },
    {
      "epoch": 2.3392857142857144,
      "grad_norm": 2.60428786277771,
      "learning_rate": 4.481927710843374e-06,
      "loss": 0.2126,
      "step": 655
    },
    {
      "epoch": 2.342857142857143,
      "grad_norm": 2.1148009300231934,
      "learning_rate": 4.457831325301205e-06,
      "loss": 0.1926,
      "step": 656
    },
    {
      "epoch": 2.3464285714285715,
      "grad_norm": 2.5608346462249756,
      "learning_rate": 4.433734939759037e-06,
      "loss": 0.215,
      "step": 657
    },
    {
      "epoch": 2.35,
      "grad_norm": 1.7258421182632446,
      "learning_rate": 4.4096385542168675e-06,
      "loss": 0.1762,
      "step": 658
    },
    {
      "epoch": 2.3535714285714286,
      "grad_norm": 2.038466691970825,
      "learning_rate": 4.385542168674699e-06,
      "loss": 0.2184,
      "step": 659
    },
    {
      "epoch": 2.357142857142857,
      "grad_norm": 2.8539483547210693,
      "learning_rate": 4.361445783132531e-06,
      "loss": 0.2438,
      "step": 660
    },
    {
      "epoch": 2.3607142857142858,
      "grad_norm": 3.2211532592773438,
      "learning_rate": 4.337349397590362e-06,
      "loss": 0.1984,
      "step": 661
    },
    {
      "epoch": 2.3642857142857143,
      "grad_norm": 2.673863172531128,
      "learning_rate": 4.313253012048193e-06,
      "loss": 0.1731,
      "step": 662
    },
    {
      "epoch": 2.367857142857143,
      "grad_norm": 1.6437487602233887,
      "learning_rate": 4.289156626506025e-06,
      "loss": 0.2053,
      "step": 663
    },
    {
      "epoch": 2.3714285714285714,
      "grad_norm": 1.814060091972351,
      "learning_rate": 4.2650602409638555e-06,
      "loss": 0.2336,
      "step": 664
    },
    {
      "epoch": 2.375,
      "grad_norm": 1.9211233854293823,
      "learning_rate": 4.240963855421687e-06,
      "loss": 0.2159,
      "step": 665
    },
    {
      "epoch": 2.3785714285714286,
      "grad_norm": 2.103301763534546,
      "learning_rate": 4.216867469879519e-06,
      "loss": 0.2286,
      "step": 666
    },
    {
      "epoch": 2.382142857142857,
      "grad_norm": 2.1561279296875,
      "learning_rate": 4.19277108433735e-06,
      "loss": 0.1799,
      "step": 667
    },
    {
      "epoch": 2.3857142857142857,
      "grad_norm": 1.9905626773834229,
      "learning_rate": 4.168674698795181e-06,
      "loss": 0.1847,
      "step": 668
    },
    {
      "epoch": 2.3892857142857142,
      "grad_norm": 2.2116012573242188,
      "learning_rate": 4.144578313253013e-06,
      "loss": 0.1995,
      "step": 669
    },
    {
      "epoch": 2.392857142857143,
      "grad_norm": 1.8957624435424805,
      "learning_rate": 4.1204819277108436e-06,
      "loss": 0.239,
      "step": 670
    },
    {
      "epoch": 2.3964285714285714,
      "grad_norm": 3.118816614151001,
      "learning_rate": 4.096385542168675e-06,
      "loss": 0.2587,
      "step": 671
    },
    {
      "epoch": 2.4,
      "grad_norm": 1.8203986883163452,
      "learning_rate": 4.072289156626506e-06,
      "loss": 0.19,
      "step": 672
    },
    {
      "epoch": 2.4035714285714285,
      "grad_norm": 2.0484273433685303,
      "learning_rate": 4.048192771084338e-06,
      "loss": 0.2004,
      "step": 673
    },
    {
      "epoch": 2.407142857142857,
      "grad_norm": 2.7074196338653564,
      "learning_rate": 4.024096385542169e-06,
      "loss": 0.2491,
      "step": 674
    },
    {
      "epoch": 2.4107142857142856,
      "grad_norm": 2.280207633972168,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.2117,
      "step": 675
    },
    {
      "epoch": 2.414285714285714,
      "grad_norm": 2.388174533843994,
      "learning_rate": 3.975903614457832e-06,
      "loss": 0.2065,
      "step": 676
    },
    {
      "epoch": 2.4178571428571427,
      "grad_norm": 2.3407816886901855,
      "learning_rate": 3.9518072289156625e-06,
      "loss": 0.2031,
      "step": 677
    },
    {
      "epoch": 2.4214285714285713,
      "grad_norm": 2.36000919342041,
      "learning_rate": 3.927710843373494e-06,
      "loss": 0.1842,
      "step": 678
    },
    {
      "epoch": 2.425,
      "grad_norm": 1.6007071733474731,
      "learning_rate": 3.903614457831326e-06,
      "loss": 0.1891,
      "step": 679
    },
    {
      "epoch": 2.4285714285714284,
      "grad_norm": 2.015000820159912,
      "learning_rate": 3.879518072289157e-06,
      "loss": 0.168,
      "step": 680
    },
    {
      "epoch": 2.432142857142857,
      "grad_norm": 1.7497719526290894,
      "learning_rate": 3.855421686746989e-06,
      "loss": 0.1835,
      "step": 681
    },
    {
      "epoch": 2.435714285714286,
      "grad_norm": 2.253354072570801,
      "learning_rate": 3.83132530120482e-06,
      "loss": 0.2319,
      "step": 682
    },
    {
      "epoch": 2.439285714285714,
      "grad_norm": 2.197131395339966,
      "learning_rate": 3.807228915662651e-06,
      "loss": 0.201,
      "step": 683
    },
    {
      "epoch": 2.442857142857143,
      "grad_norm": 1.927497148513794,
      "learning_rate": 3.7831325301204823e-06,
      "loss": 0.2013,
      "step": 684
    },
    {
      "epoch": 2.4464285714285716,
      "grad_norm": 2.320636510848999,
      "learning_rate": 3.7590361445783136e-06,
      "loss": 0.2306,
      "step": 685
    },
    {
      "epoch": 2.45,
      "grad_norm": 2.6658780574798584,
      "learning_rate": 3.7349397590361445e-06,
      "loss": 0.2424,
      "step": 686
    },
    {
      "epoch": 2.4535714285714287,
      "grad_norm": 2.0770974159240723,
      "learning_rate": 3.7108433734939763e-06,
      "loss": 0.1694,
      "step": 687
    },
    {
      "epoch": 2.4571428571428573,
      "grad_norm": 1.9169095754623413,
      "learning_rate": 3.6867469879518076e-06,
      "loss": 0.208,
      "step": 688
    },
    {
      "epoch": 2.460714285714286,
      "grad_norm": 2.306879758834839,
      "learning_rate": 3.6626506024096385e-06,
      "loss": 0.2042,
      "step": 689
    },
    {
      "epoch": 2.4642857142857144,
      "grad_norm": 2.0210697650909424,
      "learning_rate": 3.6385542168674703e-06,
      "loss": 0.2098,
      "step": 690
    },
    {
      "epoch": 2.467857142857143,
      "grad_norm": 1.7670691013336182,
      "learning_rate": 3.6144578313253016e-06,
      "loss": 0.1847,
      "step": 691
    },
    {
      "epoch": 2.4714285714285715,
      "grad_norm": 1.9172605276107788,
      "learning_rate": 3.5903614457831325e-06,
      "loss": 0.1922,
      "step": 692
    },
    {
      "epoch": 2.475,
      "grad_norm": 2.1260945796966553,
      "learning_rate": 3.5662650602409643e-06,
      "loss": 0.2169,
      "step": 693
    },
    {
      "epoch": 2.4785714285714286,
      "grad_norm": 2.2396063804626465,
      "learning_rate": 3.5421686746987956e-06,
      "loss": 0.2208,
      "step": 694
    },
    {
      "epoch": 2.482142857142857,
      "grad_norm": 1.9326386451721191,
      "learning_rate": 3.5180722891566266e-06,
      "loss": 0.1905,
      "step": 695
    },
    {
      "epoch": 2.4857142857142858,
      "grad_norm": 2.677119255065918,
      "learning_rate": 3.4939759036144583e-06,
      "loss": 0.1904,
      "step": 696
    },
    {
      "epoch": 2.4892857142857143,
      "grad_norm": 1.997118592262268,
      "learning_rate": 3.4698795180722892e-06,
      "loss": 0.1859,
      "step": 697
    },
    {
      "epoch": 2.492857142857143,
      "grad_norm": 1.6000386476516724,
      "learning_rate": 3.4457831325301206e-06,
      "loss": 0.2012,
      "step": 698
    },
    {
      "epoch": 2.4964285714285714,
      "grad_norm": 2.671445608139038,
      "learning_rate": 3.4216867469879523e-06,
      "loss": 0.1899,
      "step": 699
    },
    {
      "epoch": 2.5,
      "grad_norm": 1.9638266563415527,
      "learning_rate": 3.3975903614457832e-06,
      "loss": 0.2025,
      "step": 700
    }
  ],
  "logging_steps": 1,
  "max_steps": 840,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8774833127424000.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
