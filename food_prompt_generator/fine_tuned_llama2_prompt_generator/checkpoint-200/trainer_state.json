{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.7142857142857143,
  "eval_steps": 50,
  "global_step": 200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0035714285714285713,
      "grad_norm": 1.2351223230361938,
      "learning_rate": 0.0,
      "loss": 4.4977,
      "step": 1
    },
    {
      "epoch": 0.007142857142857143,
      "grad_norm": 1.142757773399353,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 4.2449,
      "step": 2
    },
    {
      "epoch": 0.010714285714285714,
      "grad_norm": 1.1618402004241943,
      "learning_rate": 4.000000000000001e-06,
      "loss": 4.1516,
      "step": 3
    },
    {
      "epoch": 0.014285714285714285,
      "grad_norm": 1.2743682861328125,
      "learning_rate": 6e-06,
      "loss": 4.3749,
      "step": 4
    },
    {
      "epoch": 0.017857142857142856,
      "grad_norm": 1.1161952018737793,
      "learning_rate": 8.000000000000001e-06,
      "loss": 4.0766,
      "step": 5
    },
    {
      "epoch": 0.02142857142857143,
      "grad_norm": 1.237971305847168,
      "learning_rate": 1e-05,
      "loss": 4.2567,
      "step": 6
    },
    {
      "epoch": 0.025,
      "grad_norm": 1.1448726654052734,
      "learning_rate": 1.2e-05,
      "loss": 4.2172,
      "step": 7
    },
    {
      "epoch": 0.02857142857142857,
      "grad_norm": 1.223588466644287,
      "learning_rate": 1.4e-05,
      "loss": 4.3423,
      "step": 8
    },
    {
      "epoch": 0.03214285714285714,
      "grad_norm": 1.1014832258224487,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 3.8955,
      "step": 9
    },
    {
      "epoch": 0.03571428571428571,
      "grad_norm": 1.2143946886062622,
      "learning_rate": 1.8e-05,
      "loss": 4.0908,
      "step": 10
    },
    {
      "epoch": 0.039285714285714285,
      "grad_norm": 1.319791555404663,
      "learning_rate": 2e-05,
      "loss": 4.2406,
      "step": 11
    },
    {
      "epoch": 0.04285714285714286,
      "grad_norm": 1.2103867530822754,
      "learning_rate": 1.9975903614457833e-05,
      "loss": 3.9583,
      "step": 12
    },
    {
      "epoch": 0.04642857142857143,
      "grad_norm": 1.2164217233657837,
      "learning_rate": 1.9951807228915665e-05,
      "loss": 4.0441,
      "step": 13
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.3159626722335815,
      "learning_rate": 1.9927710843373497e-05,
      "loss": 3.9948,
      "step": 14
    },
    {
      "epoch": 0.05357142857142857,
      "grad_norm": 1.5581860542297363,
      "learning_rate": 1.9903614457831325e-05,
      "loss": 4.2483,
      "step": 15
    },
    {
      "epoch": 0.05714285714285714,
      "grad_norm": 1.3834818601608276,
      "learning_rate": 1.987951807228916e-05,
      "loss": 3.9568,
      "step": 16
    },
    {
      "epoch": 0.060714285714285714,
      "grad_norm": 1.4401079416275024,
      "learning_rate": 1.985542168674699e-05,
      "loss": 4.0513,
      "step": 17
    },
    {
      "epoch": 0.06428571428571428,
      "grad_norm": 1.5064538717269897,
      "learning_rate": 1.983132530120482e-05,
      "loss": 3.9104,
      "step": 18
    },
    {
      "epoch": 0.06785714285714285,
      "grad_norm": 1.5647220611572266,
      "learning_rate": 1.9807228915662652e-05,
      "loss": 3.9984,
      "step": 19
    },
    {
      "epoch": 0.07142857142857142,
      "grad_norm": 1.5998917818069458,
      "learning_rate": 1.9783132530120484e-05,
      "loss": 4.0516,
      "step": 20
    },
    {
      "epoch": 0.075,
      "grad_norm": 1.5841845273971558,
      "learning_rate": 1.9759036144578312e-05,
      "loss": 3.8885,
      "step": 21
    },
    {
      "epoch": 0.07857142857142857,
      "grad_norm": 1.5619786977767944,
      "learning_rate": 1.9734939759036148e-05,
      "loss": 3.7881,
      "step": 22
    },
    {
      "epoch": 0.08214285714285714,
      "grad_norm": 1.6028382778167725,
      "learning_rate": 1.9710843373493976e-05,
      "loss": 3.7501,
      "step": 23
    },
    {
      "epoch": 0.08571428571428572,
      "grad_norm": 1.7312976121902466,
      "learning_rate": 1.9686746987951808e-05,
      "loss": 3.9056,
      "step": 24
    },
    {
      "epoch": 0.08928571428571429,
      "grad_norm": 1.6884418725967407,
      "learning_rate": 1.966265060240964e-05,
      "loss": 3.8343,
      "step": 25
    },
    {
      "epoch": 0.09285714285714286,
      "grad_norm": 1.657343864440918,
      "learning_rate": 1.963855421686747e-05,
      "loss": 3.7759,
      "step": 26
    },
    {
      "epoch": 0.09642857142857143,
      "grad_norm": 1.7672631740570068,
      "learning_rate": 1.9614457831325303e-05,
      "loss": 3.6951,
      "step": 27
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.8270766735076904,
      "learning_rate": 1.9590361445783135e-05,
      "loss": 3.8563,
      "step": 28
    },
    {
      "epoch": 0.10357142857142858,
      "grad_norm": 1.6442331075668335,
      "learning_rate": 1.9566265060240967e-05,
      "loss": 3.5617,
      "step": 29
    },
    {
      "epoch": 0.10714285714285714,
      "grad_norm": 1.861194133758545,
      "learning_rate": 1.9542168674698795e-05,
      "loss": 3.7459,
      "step": 30
    },
    {
      "epoch": 0.11071428571428571,
      "grad_norm": 1.996978759765625,
      "learning_rate": 1.951807228915663e-05,
      "loss": 3.7912,
      "step": 31
    },
    {
      "epoch": 0.11428571428571428,
      "grad_norm": 1.8723829984664917,
      "learning_rate": 1.949397590361446e-05,
      "loss": 3.6466,
      "step": 32
    },
    {
      "epoch": 0.11785714285714285,
      "grad_norm": 1.6257067918777466,
      "learning_rate": 1.946987951807229e-05,
      "loss": 3.4698,
      "step": 33
    },
    {
      "epoch": 0.12142857142857143,
      "grad_norm": 2.0420496463775635,
      "learning_rate": 1.9445783132530122e-05,
      "loss": 3.8206,
      "step": 34
    },
    {
      "epoch": 0.125,
      "grad_norm": 1.7446900606155396,
      "learning_rate": 1.9421686746987954e-05,
      "loss": 3.5167,
      "step": 35
    },
    {
      "epoch": 0.12857142857142856,
      "grad_norm": 1.8713101148605347,
      "learning_rate": 1.9397590361445785e-05,
      "loss": 3.6069,
      "step": 36
    },
    {
      "epoch": 0.13214285714285715,
      "grad_norm": 2.0387582778930664,
      "learning_rate": 1.9373493975903617e-05,
      "loss": 3.5755,
      "step": 37
    },
    {
      "epoch": 0.1357142857142857,
      "grad_norm": 1.8597904443740845,
      "learning_rate": 1.9349397590361446e-05,
      "loss": 3.3767,
      "step": 38
    },
    {
      "epoch": 0.1392857142857143,
      "grad_norm": 1.8979336023330688,
      "learning_rate": 1.9325301204819277e-05,
      "loss": 3.5736,
      "step": 39
    },
    {
      "epoch": 0.14285714285714285,
      "grad_norm": 1.84732186794281,
      "learning_rate": 1.930120481927711e-05,
      "loss": 3.3367,
      "step": 40
    },
    {
      "epoch": 0.14642857142857144,
      "grad_norm": 2.1052732467651367,
      "learning_rate": 1.927710843373494e-05,
      "loss": 3.5508,
      "step": 41
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.1071627140045166,
      "learning_rate": 1.9253012048192773e-05,
      "loss": 3.5187,
      "step": 42
    },
    {
      "epoch": 0.15357142857142858,
      "grad_norm": 2.019829273223877,
      "learning_rate": 1.9228915662650604e-05,
      "loss": 3.4967,
      "step": 43
    },
    {
      "epoch": 0.15714285714285714,
      "grad_norm": 1.8837368488311768,
      "learning_rate": 1.9204819277108436e-05,
      "loss": 3.3049,
      "step": 44
    },
    {
      "epoch": 0.16071428571428573,
      "grad_norm": 1.8147345781326294,
      "learning_rate": 1.9180722891566265e-05,
      "loss": 3.2879,
      "step": 45
    },
    {
      "epoch": 0.16428571428571428,
      "grad_norm": 2.0287275314331055,
      "learning_rate": 1.91566265060241e-05,
      "loss": 3.3731,
      "step": 46
    },
    {
      "epoch": 0.16785714285714284,
      "grad_norm": 1.9595811367034912,
      "learning_rate": 1.9132530120481928e-05,
      "loss": 3.226,
      "step": 47
    },
    {
      "epoch": 0.17142857142857143,
      "grad_norm": 2.048156261444092,
      "learning_rate": 1.910843373493976e-05,
      "loss": 3.3593,
      "step": 48
    },
    {
      "epoch": 0.175,
      "grad_norm": 1.9334805011749268,
      "learning_rate": 1.908433734939759e-05,
      "loss": 3.1889,
      "step": 49
    },
    {
      "epoch": 0.17857142857142858,
      "grad_norm": 1.7902711629867554,
      "learning_rate": 1.9060240963855423e-05,
      "loss": 3.1023,
      "step": 50
    },
    {
      "epoch": 0.18214285714285713,
      "grad_norm": 2.0465986728668213,
      "learning_rate": 1.9036144578313255e-05,
      "loss": 3.2817,
      "step": 51
    },
    {
      "epoch": 0.18571428571428572,
      "grad_norm": 1.9188201427459717,
      "learning_rate": 1.9012048192771087e-05,
      "loss": 3.1262,
      "step": 52
    },
    {
      "epoch": 0.18928571428571428,
      "grad_norm": 1.8897244930267334,
      "learning_rate": 1.898795180722892e-05,
      "loss": 3.0283,
      "step": 53
    },
    {
      "epoch": 0.19285714285714287,
      "grad_norm": 1.9843276739120483,
      "learning_rate": 1.8963855421686747e-05,
      "loss": 3.039,
      "step": 54
    },
    {
      "epoch": 0.19642857142857142,
      "grad_norm": 2.03045916557312,
      "learning_rate": 1.893975903614458e-05,
      "loss": 3.0167,
      "step": 55
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.0318729877471924,
      "learning_rate": 1.891566265060241e-05,
      "loss": 3.0678,
      "step": 56
    },
    {
      "epoch": 0.20357142857142857,
      "grad_norm": 1.9611940383911133,
      "learning_rate": 1.8891566265060242e-05,
      "loss": 2.976,
      "step": 57
    },
    {
      "epoch": 0.20714285714285716,
      "grad_norm": 1.9360589981079102,
      "learning_rate": 1.8867469879518074e-05,
      "loss": 2.96,
      "step": 58
    },
    {
      "epoch": 0.21071428571428572,
      "grad_norm": 1.9134842157363892,
      "learning_rate": 1.8843373493975906e-05,
      "loss": 2.8603,
      "step": 59
    },
    {
      "epoch": 0.21428571428571427,
      "grad_norm": 1.9793550968170166,
      "learning_rate": 1.8819277108433734e-05,
      "loss": 2.9287,
      "step": 60
    },
    {
      "epoch": 0.21785714285714286,
      "grad_norm": 2.059096097946167,
      "learning_rate": 1.879518072289157e-05,
      "loss": 2.8555,
      "step": 61
    },
    {
      "epoch": 0.22142857142857142,
      "grad_norm": 1.8721405267715454,
      "learning_rate": 1.8771084337349398e-05,
      "loss": 2.8062,
      "step": 62
    },
    {
      "epoch": 0.225,
      "grad_norm": 1.7886502742767334,
      "learning_rate": 1.874698795180723e-05,
      "loss": 2.7272,
      "step": 63
    },
    {
      "epoch": 0.22857142857142856,
      "grad_norm": 1.8401329517364502,
      "learning_rate": 1.872289156626506e-05,
      "loss": 2.7161,
      "step": 64
    },
    {
      "epoch": 0.23214285714285715,
      "grad_norm": 1.8457140922546387,
      "learning_rate": 1.8698795180722893e-05,
      "loss": 2.7607,
      "step": 65
    },
    {
      "epoch": 0.2357142857142857,
      "grad_norm": 1.9569587707519531,
      "learning_rate": 1.8674698795180725e-05,
      "loss": 2.7546,
      "step": 66
    },
    {
      "epoch": 0.2392857142857143,
      "grad_norm": 1.7955771684646606,
      "learning_rate": 1.8650602409638556e-05,
      "loss": 2.6997,
      "step": 67
    },
    {
      "epoch": 0.24285714285714285,
      "grad_norm": 1.732554316520691,
      "learning_rate": 1.8626506024096388e-05,
      "loss": 2.5859,
      "step": 68
    },
    {
      "epoch": 0.24642857142857144,
      "grad_norm": 1.9211989641189575,
      "learning_rate": 1.8602409638554217e-05,
      "loss": 2.7142,
      "step": 69
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.7429627180099487,
      "learning_rate": 1.8578313253012052e-05,
      "loss": 2.4876,
      "step": 70
    },
    {
      "epoch": 0.25357142857142856,
      "grad_norm": 1.7620816230773926,
      "learning_rate": 1.855421686746988e-05,
      "loss": 2.5687,
      "step": 71
    },
    {
      "epoch": 0.2571428571428571,
      "grad_norm": 2.164268970489502,
      "learning_rate": 1.8530120481927712e-05,
      "loss": 2.7445,
      "step": 72
    },
    {
      "epoch": 0.26071428571428573,
      "grad_norm": 1.8384405374526978,
      "learning_rate": 1.8506024096385544e-05,
      "loss": 2.4971,
      "step": 73
    },
    {
      "epoch": 0.2642857142857143,
      "grad_norm": 1.815026044845581,
      "learning_rate": 1.8481927710843375e-05,
      "loss": 2.3951,
      "step": 74
    },
    {
      "epoch": 0.26785714285714285,
      "grad_norm": 1.8641546964645386,
      "learning_rate": 1.8457831325301204e-05,
      "loss": 2.4314,
      "step": 75
    },
    {
      "epoch": 0.2714285714285714,
      "grad_norm": 1.952675461769104,
      "learning_rate": 1.843373493975904e-05,
      "loss": 2.5544,
      "step": 76
    },
    {
      "epoch": 0.275,
      "grad_norm": 1.9751224517822266,
      "learning_rate": 1.8409638554216867e-05,
      "loss": 2.3973,
      "step": 77
    },
    {
      "epoch": 0.2785714285714286,
      "grad_norm": 2.074291229248047,
      "learning_rate": 1.83855421686747e-05,
      "loss": 2.4502,
      "step": 78
    },
    {
      "epoch": 0.28214285714285714,
      "grad_norm": 2.013305187225342,
      "learning_rate": 1.836144578313253e-05,
      "loss": 2.3764,
      "step": 79
    },
    {
      "epoch": 0.2857142857142857,
      "grad_norm": 2.006464719772339,
      "learning_rate": 1.8337349397590363e-05,
      "loss": 2.3239,
      "step": 80
    },
    {
      "epoch": 0.2892857142857143,
      "grad_norm": 1.975691556930542,
      "learning_rate": 1.8313253012048194e-05,
      "loss": 2.1891,
      "step": 81
    },
    {
      "epoch": 0.29285714285714287,
      "grad_norm": 2.0898325443267822,
      "learning_rate": 1.8289156626506026e-05,
      "loss": 2.2363,
      "step": 82
    },
    {
      "epoch": 0.29642857142857143,
      "grad_norm": 2.281416893005371,
      "learning_rate": 1.8265060240963858e-05,
      "loss": 2.1942,
      "step": 83
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.127601146697998,
      "learning_rate": 1.8240963855421686e-05,
      "loss": 2.263,
      "step": 84
    },
    {
      "epoch": 0.30357142857142855,
      "grad_norm": 2.2393994331359863,
      "learning_rate": 1.821686746987952e-05,
      "loss": 2.1872,
      "step": 85
    },
    {
      "epoch": 0.30714285714285716,
      "grad_norm": 2.1931138038635254,
      "learning_rate": 1.819277108433735e-05,
      "loss": 2.1202,
      "step": 86
    },
    {
      "epoch": 0.3107142857142857,
      "grad_norm": 2.129633903503418,
      "learning_rate": 1.816867469879518e-05,
      "loss": 2.0962,
      "step": 87
    },
    {
      "epoch": 0.3142857142857143,
      "grad_norm": 2.090254545211792,
      "learning_rate": 1.8144578313253013e-05,
      "loss": 2.083,
      "step": 88
    },
    {
      "epoch": 0.31785714285714284,
      "grad_norm": 2.2423794269561768,
      "learning_rate": 1.8120481927710845e-05,
      "loss": 2.0047,
      "step": 89
    },
    {
      "epoch": 0.32142857142857145,
      "grad_norm": 2.0850932598114014,
      "learning_rate": 1.8096385542168677e-05,
      "loss": 1.9767,
      "step": 90
    },
    {
      "epoch": 0.325,
      "grad_norm": 1.8836002349853516,
      "learning_rate": 1.807228915662651e-05,
      "loss": 1.86,
      "step": 91
    },
    {
      "epoch": 0.32857142857142857,
      "grad_norm": 2.0327930450439453,
      "learning_rate": 1.8048192771084337e-05,
      "loss": 2.001,
      "step": 92
    },
    {
      "epoch": 0.33214285714285713,
      "grad_norm": 1.924464225769043,
      "learning_rate": 1.802409638554217e-05,
      "loss": 1.8488,
      "step": 93
    },
    {
      "epoch": 0.3357142857142857,
      "grad_norm": 1.8560526371002197,
      "learning_rate": 1.8e-05,
      "loss": 1.9049,
      "step": 94
    },
    {
      "epoch": 0.3392857142857143,
      "grad_norm": 1.7688238620758057,
      "learning_rate": 1.7975903614457832e-05,
      "loss": 1.7707,
      "step": 95
    },
    {
      "epoch": 0.34285714285714286,
      "grad_norm": 1.8896163702011108,
      "learning_rate": 1.7951807228915664e-05,
      "loss": 1.8032,
      "step": 96
    },
    {
      "epoch": 0.3464285714285714,
      "grad_norm": 1.8001446723937988,
      "learning_rate": 1.7927710843373496e-05,
      "loss": 1.7964,
      "step": 97
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.8900786638259888,
      "learning_rate": 1.7903614457831327e-05,
      "loss": 1.7969,
      "step": 98
    },
    {
      "epoch": 0.3535714285714286,
      "grad_norm": 1.8385177850723267,
      "learning_rate": 1.7879518072289156e-05,
      "loss": 1.7695,
      "step": 99
    },
    {
      "epoch": 0.35714285714285715,
      "grad_norm": 1.890625,
      "learning_rate": 1.785542168674699e-05,
      "loss": 1.7036,
      "step": 100
    },
    {
      "epoch": 0.3607142857142857,
      "grad_norm": 1.8775233030319214,
      "learning_rate": 1.783132530120482e-05,
      "loss": 1.6474,
      "step": 101
    },
    {
      "epoch": 0.36428571428571427,
      "grad_norm": 1.8851613998413086,
      "learning_rate": 1.780722891566265e-05,
      "loss": 1.6921,
      "step": 102
    },
    {
      "epoch": 0.3678571428571429,
      "grad_norm": 1.9728379249572754,
      "learning_rate": 1.7783132530120483e-05,
      "loss": 1.6447,
      "step": 103
    },
    {
      "epoch": 0.37142857142857144,
      "grad_norm": 1.870786190032959,
      "learning_rate": 1.7759036144578315e-05,
      "loss": 1.6109,
      "step": 104
    },
    {
      "epoch": 0.375,
      "grad_norm": 1.8838322162628174,
      "learning_rate": 1.7734939759036146e-05,
      "loss": 1.5994,
      "step": 105
    },
    {
      "epoch": 0.37857142857142856,
      "grad_norm": 1.9622297286987305,
      "learning_rate": 1.7710843373493978e-05,
      "loss": 1.5546,
      "step": 106
    },
    {
      "epoch": 0.3821428571428571,
      "grad_norm": 2.005788564682007,
      "learning_rate": 1.768674698795181e-05,
      "loss": 1.6464,
      "step": 107
    },
    {
      "epoch": 0.38571428571428573,
      "grad_norm": 1.8062478303909302,
      "learning_rate": 1.766265060240964e-05,
      "loss": 1.5206,
      "step": 108
    },
    {
      "epoch": 0.3892857142857143,
      "grad_norm": 1.8345874547958374,
      "learning_rate": 1.763855421686747e-05,
      "loss": 1.5111,
      "step": 109
    },
    {
      "epoch": 0.39285714285714285,
      "grad_norm": 1.8258323669433594,
      "learning_rate": 1.7614457831325302e-05,
      "loss": 1.4062,
      "step": 110
    },
    {
      "epoch": 0.3964285714285714,
      "grad_norm": 1.8945640325546265,
      "learning_rate": 1.7590361445783134e-05,
      "loss": 1.4446,
      "step": 111
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.000694513320923,
      "learning_rate": 1.7566265060240965e-05,
      "loss": 1.443,
      "step": 112
    },
    {
      "epoch": 0.4035714285714286,
      "grad_norm": 1.9519555568695068,
      "learning_rate": 1.7542168674698797e-05,
      "loss": 1.3272,
      "step": 113
    },
    {
      "epoch": 0.40714285714285714,
      "grad_norm": 2.088046073913574,
      "learning_rate": 1.7518072289156625e-05,
      "loss": 1.2992,
      "step": 114
    },
    {
      "epoch": 0.4107142857142857,
      "grad_norm": 2.092481851577759,
      "learning_rate": 1.749397590361446e-05,
      "loss": 1.2912,
      "step": 115
    },
    {
      "epoch": 0.4142857142857143,
      "grad_norm": 2.075457811355591,
      "learning_rate": 1.746987951807229e-05,
      "loss": 1.2543,
      "step": 116
    },
    {
      "epoch": 0.41785714285714287,
      "grad_norm": 2.2946720123291016,
      "learning_rate": 1.7445783132530124e-05,
      "loss": 1.2474,
      "step": 117
    },
    {
      "epoch": 0.42142857142857143,
      "grad_norm": 2.158531904220581,
      "learning_rate": 1.7421686746987953e-05,
      "loss": 1.2269,
      "step": 118
    },
    {
      "epoch": 0.425,
      "grad_norm": 2.307044267654419,
      "learning_rate": 1.7397590361445784e-05,
      "loss": 1.245,
      "step": 119
    },
    {
      "epoch": 0.42857142857142855,
      "grad_norm": 2.1518502235412598,
      "learning_rate": 1.7373493975903616e-05,
      "loss": 1.1478,
      "step": 120
    },
    {
      "epoch": 0.43214285714285716,
      "grad_norm": 2.381375312805176,
      "learning_rate": 1.7349397590361448e-05,
      "loss": 1.1759,
      "step": 121
    },
    {
      "epoch": 0.4357142857142857,
      "grad_norm": 2.6364505290985107,
      "learning_rate": 1.732530120481928e-05,
      "loss": 1.197,
      "step": 122
    },
    {
      "epoch": 0.4392857142857143,
      "grad_norm": 2.3618199825286865,
      "learning_rate": 1.730120481927711e-05,
      "loss": 1.1449,
      "step": 123
    },
    {
      "epoch": 0.44285714285714284,
      "grad_norm": 2.5355849266052246,
      "learning_rate": 1.7277108433734943e-05,
      "loss": 1.1575,
      "step": 124
    },
    {
      "epoch": 0.44642857142857145,
      "grad_norm": 3.1072680950164795,
      "learning_rate": 1.725301204819277e-05,
      "loss": 1.1226,
      "step": 125
    },
    {
      "epoch": 0.45,
      "grad_norm": 3.2643802165985107,
      "learning_rate": 1.7228915662650603e-05,
      "loss": 1.1575,
      "step": 126
    },
    {
      "epoch": 0.45357142857142857,
      "grad_norm": 2.9944562911987305,
      "learning_rate": 1.7204819277108435e-05,
      "loss": 1.0501,
      "step": 127
    },
    {
      "epoch": 0.45714285714285713,
      "grad_norm": 3.5879790782928467,
      "learning_rate": 1.7180722891566267e-05,
      "loss": 1.0681,
      "step": 128
    },
    {
      "epoch": 0.4607142857142857,
      "grad_norm": 3.2143406867980957,
      "learning_rate": 1.71566265060241e-05,
      "loss": 1.0566,
      "step": 129
    },
    {
      "epoch": 0.4642857142857143,
      "grad_norm": 3.297520875930786,
      "learning_rate": 1.713253012048193e-05,
      "loss": 0.9982,
      "step": 130
    },
    {
      "epoch": 0.46785714285714286,
      "grad_norm": 3.380012273788452,
      "learning_rate": 1.710843373493976e-05,
      "loss": 0.8513,
      "step": 131
    },
    {
      "epoch": 0.4714285714285714,
      "grad_norm": 3.5004498958587646,
      "learning_rate": 1.7084337349397594e-05,
      "loss": 0.9701,
      "step": 132
    },
    {
      "epoch": 0.475,
      "grad_norm": 3.398834466934204,
      "learning_rate": 1.7060240963855422e-05,
      "loss": 0.8896,
      "step": 133
    },
    {
      "epoch": 0.4785714285714286,
      "grad_norm": 2.536311149597168,
      "learning_rate": 1.7036144578313254e-05,
      "loss": 0.9294,
      "step": 134
    },
    {
      "epoch": 0.48214285714285715,
      "grad_norm": 2.551471471786499,
      "learning_rate": 1.7012048192771086e-05,
      "loss": 0.8537,
      "step": 135
    },
    {
      "epoch": 0.4857142857142857,
      "grad_norm": 2.1202259063720703,
      "learning_rate": 1.6987951807228917e-05,
      "loss": 0.9186,
      "step": 136
    },
    {
      "epoch": 0.48928571428571427,
      "grad_norm": 2.361194133758545,
      "learning_rate": 1.696385542168675e-05,
      "loss": 0.9269,
      "step": 137
    },
    {
      "epoch": 0.4928571428571429,
      "grad_norm": 2.0172808170318604,
      "learning_rate": 1.693975903614458e-05,
      "loss": 0.9212,
      "step": 138
    },
    {
      "epoch": 0.49642857142857144,
      "grad_norm": 1.5350641012191772,
      "learning_rate": 1.6915662650602413e-05,
      "loss": 0.823,
      "step": 139
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.4327404499053955,
      "learning_rate": 1.689156626506024e-05,
      "loss": 0.8043,
      "step": 140
    },
    {
      "epoch": 0.5035714285714286,
      "grad_norm": 1.5267105102539062,
      "learning_rate": 1.6867469879518076e-05,
      "loss": 0.8009,
      "step": 141
    },
    {
      "epoch": 0.5071428571428571,
      "grad_norm": 1.4948630332946777,
      "learning_rate": 1.6843373493975905e-05,
      "loss": 0.8004,
      "step": 142
    },
    {
      "epoch": 0.5107142857142857,
      "grad_norm": 1.6614656448364258,
      "learning_rate": 1.6819277108433736e-05,
      "loss": 0.7974,
      "step": 143
    },
    {
      "epoch": 0.5142857142857142,
      "grad_norm": 1.5509579181671143,
      "learning_rate": 1.6795180722891568e-05,
      "loss": 0.7682,
      "step": 144
    },
    {
      "epoch": 0.5178571428571429,
      "grad_norm": 1.7512389421463013,
      "learning_rate": 1.67710843373494e-05,
      "loss": 0.7844,
      "step": 145
    },
    {
      "epoch": 0.5214285714285715,
      "grad_norm": 1.7587946653366089,
      "learning_rate": 1.6746987951807228e-05,
      "loss": 0.7869,
      "step": 146
    },
    {
      "epoch": 0.525,
      "grad_norm": 1.7757728099822998,
      "learning_rate": 1.6722891566265063e-05,
      "loss": 0.7095,
      "step": 147
    },
    {
      "epoch": 0.5285714285714286,
      "grad_norm": 2.190554141998291,
      "learning_rate": 1.6698795180722892e-05,
      "loss": 0.6238,
      "step": 148
    },
    {
      "epoch": 0.5321428571428571,
      "grad_norm": 1.9274908304214478,
      "learning_rate": 1.6674698795180724e-05,
      "loss": 0.7152,
      "step": 149
    },
    {
      "epoch": 0.5357142857142857,
      "grad_norm": 1.9670509099960327,
      "learning_rate": 1.6650602409638555e-05,
      "loss": 0.7125,
      "step": 150
    },
    {
      "epoch": 0.5392857142857143,
      "grad_norm": 1.7576467990875244,
      "learning_rate": 1.6626506024096387e-05,
      "loss": 0.6305,
      "step": 151
    },
    {
      "epoch": 0.5428571428571428,
      "grad_norm": 2.546538829803467,
      "learning_rate": 1.660240963855422e-05,
      "loss": 0.7013,
      "step": 152
    },
    {
      "epoch": 0.5464285714285714,
      "grad_norm": 1.9533451795578003,
      "learning_rate": 1.657831325301205e-05,
      "loss": 0.6407,
      "step": 153
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.6285016536712646,
      "learning_rate": 1.6554216867469882e-05,
      "loss": 0.5955,
      "step": 154
    },
    {
      "epoch": 0.5535714285714286,
      "grad_norm": 3.046978712081909,
      "learning_rate": 1.653012048192771e-05,
      "loss": 0.6362,
      "step": 155
    },
    {
      "epoch": 0.5571428571428572,
      "grad_norm": 1.884706735610962,
      "learning_rate": 1.6506024096385546e-05,
      "loss": 0.5186,
      "step": 156
    },
    {
      "epoch": 0.5607142857142857,
      "grad_norm": 1.8673489093780518,
      "learning_rate": 1.6481927710843374e-05,
      "loss": 0.6017,
      "step": 157
    },
    {
      "epoch": 0.5642857142857143,
      "grad_norm": 1.4769959449768066,
      "learning_rate": 1.6457831325301206e-05,
      "loss": 0.6116,
      "step": 158
    },
    {
      "epoch": 0.5678571428571428,
      "grad_norm": 1.307189702987671,
      "learning_rate": 1.6433734939759038e-05,
      "loss": 0.5451,
      "step": 159
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 1.886917233467102,
      "learning_rate": 1.640963855421687e-05,
      "loss": 0.6059,
      "step": 160
    },
    {
      "epoch": 0.575,
      "grad_norm": 2.040921449661255,
      "learning_rate": 1.63855421686747e-05,
      "loss": 0.5557,
      "step": 161
    },
    {
      "epoch": 0.5785714285714286,
      "grad_norm": 1.3009649515151978,
      "learning_rate": 1.6361445783132533e-05,
      "loss": 0.5417,
      "step": 162
    },
    {
      "epoch": 0.5821428571428572,
      "grad_norm": 1.9869722127914429,
      "learning_rate": 1.633734939759036e-05,
      "loss": 0.49,
      "step": 163
    },
    {
      "epoch": 0.5857142857142857,
      "grad_norm": 3.1084508895874023,
      "learning_rate": 1.6313253012048193e-05,
      "loss": 0.5229,
      "step": 164
    },
    {
      "epoch": 0.5892857142857143,
      "grad_norm": 1.509081482887268,
      "learning_rate": 1.6289156626506025e-05,
      "loss": 0.5385,
      "step": 165
    },
    {
      "epoch": 0.5928571428571429,
      "grad_norm": 2.156371593475342,
      "learning_rate": 1.6265060240963857e-05,
      "loss": 0.5253,
      "step": 166
    },
    {
      "epoch": 0.5964285714285714,
      "grad_norm": 1.8192522525787354,
      "learning_rate": 1.624096385542169e-05,
      "loss": 0.5182,
      "step": 167
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.628049612045288,
      "learning_rate": 1.621686746987952e-05,
      "loss": 0.5075,
      "step": 168
    },
    {
      "epoch": 0.6035714285714285,
      "grad_norm": 1.1556060314178467,
      "learning_rate": 1.6192771084337352e-05,
      "loss": 0.4877,
      "step": 169
    },
    {
      "epoch": 0.6071428571428571,
      "grad_norm": 1.3304344415664673,
      "learning_rate": 1.616867469879518e-05,
      "loss": 0.5063,
      "step": 170
    },
    {
      "epoch": 0.6107142857142858,
      "grad_norm": 1.6389119625091553,
      "learning_rate": 1.6144578313253015e-05,
      "loss": 0.4779,
      "step": 171
    },
    {
      "epoch": 0.6142857142857143,
      "grad_norm": 4.935943603515625,
      "learning_rate": 1.6120481927710844e-05,
      "loss": 0.539,
      "step": 172
    },
    {
      "epoch": 0.6178571428571429,
      "grad_norm": 1.8521995544433594,
      "learning_rate": 1.6096385542168676e-05,
      "loss": 0.44,
      "step": 173
    },
    {
      "epoch": 0.6214285714285714,
      "grad_norm": 1.5498729944229126,
      "learning_rate": 1.6072289156626507e-05,
      "loss": 0.4789,
      "step": 174
    },
    {
      "epoch": 0.625,
      "grad_norm": 1.6099116802215576,
      "learning_rate": 1.604819277108434e-05,
      "loss": 0.4563,
      "step": 175
    },
    {
      "epoch": 0.6285714285714286,
      "grad_norm": 1.2104287147521973,
      "learning_rate": 1.602409638554217e-05,
      "loss": 0.5012,
      "step": 176
    },
    {
      "epoch": 0.6321428571428571,
      "grad_norm": 2.848482847213745,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.4302,
      "step": 177
    },
    {
      "epoch": 0.6357142857142857,
      "grad_norm": 1.8996837139129639,
      "learning_rate": 1.5975903614457834e-05,
      "loss": 0.5246,
      "step": 178
    },
    {
      "epoch": 0.6392857142857142,
      "grad_norm": 1.8222159147262573,
      "learning_rate": 1.5951807228915663e-05,
      "loss": 0.5045,
      "step": 179
    },
    {
      "epoch": 0.6428571428571429,
      "grad_norm": 1.624201774597168,
      "learning_rate": 1.5927710843373495e-05,
      "loss": 0.4575,
      "step": 180
    },
    {
      "epoch": 0.6464285714285715,
      "grad_norm": 2.5797853469848633,
      "learning_rate": 1.5903614457831326e-05,
      "loss": 0.4227,
      "step": 181
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.081059694290161,
      "learning_rate": 1.5879518072289158e-05,
      "loss": 0.4672,
      "step": 182
    },
    {
      "epoch": 0.6535714285714286,
      "grad_norm": 1.0499690771102905,
      "learning_rate": 1.585542168674699e-05,
      "loss": 0.4209,
      "step": 183
    },
    {
      "epoch": 0.6571428571428571,
      "grad_norm": 1.2750873565673828,
      "learning_rate": 1.583132530120482e-05,
      "loss": 0.4285,
      "step": 184
    },
    {
      "epoch": 0.6607142857142857,
      "grad_norm": 1.5342624187469482,
      "learning_rate": 1.580722891566265e-05,
      "loss": 0.4953,
      "step": 185
    },
    {
      "epoch": 0.6642857142857143,
      "grad_norm": 1.0981463193893433,
      "learning_rate": 1.5783132530120485e-05,
      "loss": 0.3818,
      "step": 186
    },
    {
      "epoch": 0.6678571428571428,
      "grad_norm": 5.615961074829102,
      "learning_rate": 1.5759036144578313e-05,
      "loss": 0.4605,
      "step": 187
    },
    {
      "epoch": 0.6714285714285714,
      "grad_norm": 5.596950054168701,
      "learning_rate": 1.5734939759036145e-05,
      "loss": 0.4195,
      "step": 188
    },
    {
      "epoch": 0.675,
      "grad_norm": 3.9371328353881836,
      "learning_rate": 1.5710843373493977e-05,
      "loss": 0.3986,
      "step": 189
    },
    {
      "epoch": 0.6785714285714286,
      "grad_norm": 4.605801105499268,
      "learning_rate": 1.568674698795181e-05,
      "loss": 0.4488,
      "step": 190
    },
    {
      "epoch": 0.6821428571428572,
      "grad_norm": 2.6569457054138184,
      "learning_rate": 1.566265060240964e-05,
      "loss": 0.403,
      "step": 191
    },
    {
      "epoch": 0.6857142857142857,
      "grad_norm": 2.703089475631714,
      "learning_rate": 1.5638554216867472e-05,
      "loss": 0.3677,
      "step": 192
    },
    {
      "epoch": 0.6892857142857143,
      "grad_norm": 1.173147201538086,
      "learning_rate": 1.5614457831325304e-05,
      "loss": 0.3827,
      "step": 193
    },
    {
      "epoch": 0.6928571428571428,
      "grad_norm": 2.2159297466278076,
      "learning_rate": 1.5590361445783132e-05,
      "loss": 0.4195,
      "step": 194
    },
    {
      "epoch": 0.6964285714285714,
      "grad_norm": 3.6749091148376465,
      "learning_rate": 1.5566265060240968e-05,
      "loss": 0.4461,
      "step": 195
    },
    {
      "epoch": 0.7,
      "grad_norm": 3.1826021671295166,
      "learning_rate": 1.5542168674698796e-05,
      "loss": 0.3849,
      "step": 196
    },
    {
      "epoch": 0.7035714285714286,
      "grad_norm": 5.944183349609375,
      "learning_rate": 1.5518072289156628e-05,
      "loss": 0.505,
      "step": 197
    },
    {
      "epoch": 0.7071428571428572,
      "grad_norm": 4.631973743438721,
      "learning_rate": 1.549397590361446e-05,
      "loss": 0.3987,
      "step": 198
    },
    {
      "epoch": 0.7107142857142857,
      "grad_norm": 3.8134377002716064,
      "learning_rate": 1.546987951807229e-05,
      "loss": 0.3921,
      "step": 199
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 1.6026555299758911,
      "learning_rate": 1.544578313253012e-05,
      "loss": 0.4361,
      "step": 200
    }
  ],
  "logging_steps": 1,
  "max_steps": 840,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2507095179264000.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
